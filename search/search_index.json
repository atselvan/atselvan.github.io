{
    "docs": [
        {
            "location": "/", 
            "text": "Welcome to the documentation of Private Square", 
            "title": "Welcome"
        }, 
        {
            "location": "/#welcome-to-the-documentation-of-private-square", 
            "text": "", 
            "title": "Welcome to the documentation of Private Square"
        }, 
        {
            "location": "/blog/cicd-fundamentals/", 
            "text": "CI/CD Fundamentals\n\n\nWhat is Continuous Intergration CI?\n\n\nContinuous integration is a software development practice where members of a team integrate their work frequently\n\n\n\n\nAutomate build and test executions of components\n\n\nBuild very often (eg. per commit) to detectregressions quickly\n\n\nTest often (unit and integration tests)\n\n\nAutomate regular code quality analysis exections\n\n\n\n\n\n\nWhat is Continuous Delivery?\n\n\n\n\nWhile CI lets you auomate the software build, scan and test process, CD automates the full application delivery pipeline taking new features and code from development to staging to production.\n\n\nCD is the ability to get new features, configuration changes, bug fixes into production or into the hands of the users safely and quickly in a sustainable way\n\n\n\n\n\n\nContinuous delivery vs continuous deployment\n\n\nContinuous delivery is a series of practices designed to ensure that code can be rapidly and safely deployed to production by delivering every change to a production-like environment and ensuring business applications and services function as expected through rigorous automated testing. Since every change is delivered to a staging environment using complete automation, you can have confidence the application can be deployed to production with a push of a button when the business is ready.\n\n\nContinuous deployment is the next step of continuous delivery: Every change that passes the automated tests is deployed to production automatically. Continuous deployment should be the goal of most companies that are not constrained by regulatory or other requirements.\n\n\n\n\nWhile continuous deployment may not be right for every company, continuous delivery is an absolute requirement of DevOps practices. Only when you continuously deliver your code can you have true confidence that your changes will be serving value to your customers within minutes of pushing the \"go\" button, and that you can actually push that button any time the business is ready for it.\n\n\nCICD, Why do it?\n\n\n\n\nMake releases painless\n\n\nReduce time to market\n\n\nIncrease software quality and stability\n\n\nReduce cost of ongoing software development\n\n\nSpeed up the feedback loop\n\n\n\n\nHow long would it take to your organization to deploy a changes that involves just one line of code?\n\n\nReferences\n\n\n\n\nCloudbees trainings\n\n\nContinuous delivery Vs continuous deployment", 
            "title": "CICD"
        }, 
        {
            "location": "/blog/cicd-fundamentals/#cicd-fundamentals", 
            "text": "", 
            "title": "CI/CD Fundamentals"
        }, 
        {
            "location": "/blog/cicd-fundamentals/#what-is-continuous-intergration-ci", 
            "text": "Continuous integration is a software development practice where members of a team integrate their work frequently   Automate build and test executions of components  Build very often (eg. per commit) to detectregressions quickly  Test often (unit and integration tests)  Automate regular code quality analysis exections", 
            "title": "What is Continuous Intergration CI?"
        }, 
        {
            "location": "/blog/cicd-fundamentals/#what-is-continuous-delivery", 
            "text": "While CI lets you auomate the software build, scan and test process, CD automates the full application delivery pipeline taking new features and code from development to staging to production.  CD is the ability to get new features, configuration changes, bug fixes into production or into the hands of the users safely and quickly in a sustainable way", 
            "title": "What is Continuous Delivery?"
        }, 
        {
            "location": "/blog/cicd-fundamentals/#continuous-delivery-vs-continuous-deployment", 
            "text": "Continuous delivery is a series of practices designed to ensure that code can be rapidly and safely deployed to production by delivering every change to a production-like environment and ensuring business applications and services function as expected through rigorous automated testing. Since every change is delivered to a staging environment using complete automation, you can have confidence the application can be deployed to production with a push of a button when the business is ready.  Continuous deployment is the next step of continuous delivery: Every change that passes the automated tests is deployed to production automatically. Continuous deployment should be the goal of most companies that are not constrained by regulatory or other requirements.   While continuous deployment may not be right for every company, continuous delivery is an absolute requirement of DevOps practices. Only when you continuously deliver your code can you have true confidence that your changes will be serving value to your customers within minutes of pushing the \"go\" button, and that you can actually push that button any time the business is ready for it.", 
            "title": "Continuous delivery vs continuous deployment"
        }, 
        {
            "location": "/blog/cicd-fundamentals/#cicd-why-do-it", 
            "text": "Make releases painless  Reduce time to market  Increase software quality and stability  Reduce cost of ongoing software development  Speed up the feedback loop   How long would it take to your organization to deploy a changes that involves just one line of code?", 
            "title": "CICD, Why do it?"
        }, 
        {
            "location": "/blog/cicd-fundamentals/#references", 
            "text": "Cloudbees trainings  Continuous delivery Vs continuous deployment", 
            "title": "References"
        }, 
        {
            "location": "/blog/networking-fundamentals/", 
            "text": "Networking Fundamentals\n\n\nWhat is the internet?\n\n\nThe internet is a huge network of computing devices communicating with each other based on a pre-agreed set of rules called protocols.\n\n\n\n\nThe internet is a global computer network providing a variety of information and communication facilities, consisting of interconnected networks using standardized communication protocols. (google definition)\n\n\n\n\n\n\nHow is this network formed and how does it work?\n\n\nThe edge devices that are part of this network are called hosts or end systems. For enample: Laptops, mobiles are the end systems. The end systems are connected by a network of communication links and packet switches. The communication links are made up of physical connections made of copper wires, fiber optics, radio spectrum etc. One end system sends data to another by segmenting the data into small segments with header bytes on them. These packages of information are called packets and are sent through the network to the destination end system where they are reassembled into the original data. A packet switch is responsible for routing the packets to its destination. The packet switch takes a packet arriving on one of its incoming communication links and forwards that packet on one of its outgoing communication links. Our router is a packet switch. The sequence of communication links and packet switches traversed by a packet in known as the route through the network.\n\n\n\n\nThere is beautiful analogy presented in the book Computer Networking by Kurose and Ross. It says, if a factory needs to move a large amount of cargo to some destination warehouse located thousands of kilometers away, then, the cargo is first segmented and loaded into a fleet of trucks. Each of the trucks then independently travels through the network of highways, roads, and intersections to the destination warehouse. At the destination warehouse, the cargo is unloaded and grouped with the rest of the cargo arriving from the same shipment. Thus, in many ways, packets are analogous to trucks, communication links analogous to highways and roads. Packet switches are analogous to intersections, and end systems are analogous to destination buildings.\n\n\n\n\nWhat are ISPs, TCP/IP and RFCs?\n\n\nISPs\n\n\nEnd systems access the internet through \nInternet Service Provider(ISPs)\n. ISPs include local cable or telephone companies. Each ISPs is in itself a network of packet switches and communication links. These ISPs are also interconnected. Lower-tier ISPs are interconnected through national and international upper-tier ISPs such as AT\nT and Sprint.\n\n\nTCP/IP\n\n\nAll the component of this network run protocols that control the sending and receiving of information. A protocol defines the format and the order of the messages exchanged between two or more communicating entities, as well as the actions taken on the transmission and/or receipt of a message or other events. The \nTransmission Control Protocol(TCP)\n and the \nInternet Protocol(IP)\n are the two of the most important protocols that are sent and received among the routers and end systems. The internet\u2019s principle protocols are collectively known as TCP/IP.\n\n\nIEFT and RFCs\n\n\nThese protocols are most important for the unanimous functioning and thus important that everyone agrees on what each and every protocol does. These Internet standards are developed by the \nInternet Engineering Task Force(IETF)\n. The IETF standard documents are called \nrequest for comments(RFCs)\n.\n\n\nHow does one application running on one end system instructs the Internet to deliver data to another software running on another end system?\n\n\nEnd systems attached to the Internet, provide an Application Programming Interface(API) that specifies the rules for this process. \n\n\n\n\nTaking an analogy from the same book: Suppose Alice wants to send a letter to Bob using the postal service. Alice, of course, can\u2019t just write the letter(the data) and drop the letter out her window. Instead, the postal service requires that Alice put the letter in an envelope; write Bob\u2019s full name, address, and zip code in the center of the envelope; seal the envelope; put a stamp in the upper-right-hand corner of the envelope; and finally, drop the envelope into an official postal service mailbox. Thus, the postal service has its own \u201cpostal service API\u201d, or set of rules, that Alice must follow to have the postal service deliver her letter to Bob.\n\n\n\n\nIn a similar manner, the internet has an API that the software sending data must follow to have the internet deliver the data to the software that will receive the data.\n\n\nWhat are client and server program and P2P architecture?\n\n\nA client program is a program running on one end system that requests and receives a service from a server program running on another end system. The web browser is an example of a client program and Nginx or NodeJS or Tomcat is an example of a server program.\n\n\nNot all Internet application today consists of pure client programs interacting with pure server programs. Increasingly, many application is peer-to-peer(P2P) applications, in which end systems interact and run programs that perform both client and server functions. For example, in P2P file-sharing applications(such as BitTorrent or eMule), the program in the user\u2019s end system act as a client when it requests a file from another peer; and the program acts as a server when it sends a file to another peer.\n\n\nWhat are LAN and WAN?\n\n\nLAN\n\n\nLocal Area Network (LAN)\n is a computer network, which is limited to a small office, a single building, multiple buildings inside a campus etc. Typically a LAN is a private network owned and maintained by a single organization.\n\n\nWAN\n\n\nA \nWide Area Network (WAN)\n spans over multiple geographic locations, which is composed of multiple LANs. ISPs provide the connectivity solutions for WAN.\n\n\nWhat is an IP address?\n\n\nFor one device to communicate with another, it needs an IP address, and it must be unique. If there is another device on the same network with the same IP there will be an IP address conflict and both devices will lose network capability until this is resolved.\n\n\nThe IP address consists of 4 numbers separated by decimals. The IP address itself is separated into a network address and a host address. This means that one part of the IP address identifies the computer network ID and the other part identifies the host ID.\nAs an example, an IP address of 192.168.0.11 with subnet mask 255.255.255.0 uses the first 3 numbers to identify the network and the last number to identify the host. So, the network id would be 192.168.0 and the host id would be 11. Devices can only communicate with other devices on the same network id. In other words, communication will work between 2 devices with IPs 192.168.0.221 and 192.168.0.11 respectively but neither can communicate with 192.168.1.31 because it is part of the 192.168.1 network.\n\n\nSubnet Mask\n : As a general rule wherever there is a 255 in the subnet mask then the corresponding number of the IP address is part of the network id; where there is 0 in the subnet mask the corresponding number in the IP address is part of the host id. For an IP address of 192.168.0.1 with a subnet mask of 255.0.0.0. This tells the device that the first number of the IP address is to be used as the network address and the last 3 are to be used as the host id. In this example, the computer network would be 192.x.x.x. As long as another computer has the same subnet mask and an IP address starting with 192 they can communicate with each other. If the subnet mask was 255.255.0.0 then this means that the first 2 numbers identify the network instead (192.168.x.x). Therefore to be on the same network both devices must have IP addresses starting with 192.168.\n\n\nHow do devices on different networks communicate?\n\n\nCommunication across different network IDs take place with the help of a router. A router is a network device with 2 \nnetwork interfaces (NICs)\n, each being on separate network ids. So, we may have 2 networks; 192.168.1.x and 192.168.2.x. On one NIC the router would have the IP address 192.168.1.1 and on the other, it would have an IP address of 192.168.2.1. Devices on the 192.168.1.x network can now communicate with devices on the 192.168.2.x network via the router.\n\n\nHow does the data travel from source end system to destination end system?\n\n\nThe default gateway is where a network device sends traffic to if it doesn\u2019t know the destination IP address. The default gateway is always a router.\nWhen a network device tries to communicate with another on the same network it sends the data directly to it. If it is on a separate network it forwards the data to whatever IP address is specified in the default gateway. This is because it doesn\u2019t know of this other network and it needs to send the data to a gateway out of its own network. This is why we always put the IP address of the router in the default gateway field. Because a router will be attached to multiple networks, so it knows where these other networks are and it can route traffic to them. Routers also have default gateways so that if they don\u2019t know where the destination is then they can also send the data to its own default gateway. This continues up the IP network hierarchy until it eventually finds a router that is part of the destination network. This last router knows where the destination is and sends it on its way.\n\n\nWhat is DHCP?\n\n\nNetwork devices need to be configured with an IP address, subnet mask and default gateway that will be unique to that network. Generally, we don\u2019t manually configure them but are configured automatically using DHCP servers. DHCP stands for \nDynamic Host Configuration Protocol\n. Servers and some routers can be configured to act as a DHCP server. It allots the IP addresses to the connecting devices so to prevent IP address conflicts.\n\n\nHow does a router function?\n\n\nA router should have at least two \nnetwork cards (NICs)\n, one physically connected to one network and the other physically connected to another network. A router can connect any number of networks together providing it has a dedicated NIC for each network.\n\n\nRouters also learn which are the fastest routes and use them first. Each route the router knows of has a metric value assigned to it. A metric value is basically a preference number. If there are two routes to the same destination then the one with the lowest metric is assumed to be the most efficient. Routers will always use this route first until it fails, in which case it will then try the route with the next lowest metric and so on.\n\n\nAll network devices that use the TCP/IP protocol have a routing table. On Linux based system run netstat -rn command to view this table. All devices use their routing table to determine where to send packets. When a device sends packets to another device, it looks at its routing table to determine the best route possible. If it finds the destination address is \u201con-link\u201d it knows that it is a part of the same subnet as the destination and sends the packets directly to the device. If not it forwards the packet onto whatever is in the gateway field of the matching route entry. This same process is repeated at every router/hop along the way until it eventually arrives at a router that is part of the destination network.\n\n\nWhat is a port?\n\n\nIn the internet protocol suite, a port is an endpoint of communication in an operating system, in software, it is a logical construct that identifies a specific process or a type of network service.\n\n\nA port is always associated with an IP address of a host and the protocol of the communication. A port is identified for each address and protocol by a 16-bit number, commonly known as the port number. For example, an address may be \u201cprotocol: TCP, IP address: 1.2.3.4, port number: 80\u201d, which is written as 1.2.3.4:80 when the protocol is known from context.\n\n\nThe port, which is the number after \u201c:\u201d in the IP address defines the port on which the data has to be sent.By default, HTTP uses port 80 and HTTPS uses port 443, and we don\u2019t add them in the browser but are implicitly handled by the browsers. But a URL like \nhttp://www.example.com:8080/path/\n specifies that the web browser connects instead to port 8080 of the HTTP server.\n\n\nWhat is port forwarding?\n\n\nPort forwarding or port mapping is an application of \nnetwork address translation (NAT)\n that redirects a communication request from one address and port number combination to another while the packets are traversing a network gateway, such as a router or firewall. This technique is most commonly used to make services on a host residing on a protected or masqueraded (internal) network available to hosts on the opposite side of the gateway (external network), by remapping the destination IP address and port number of the communication to an internal host.\n\n\nWhat this mean is that when a request arrives at a router at a specific port then it reroutes this request to a server in the local network of the router so to be able to process it (if configured on NAT settings). So, it in a way works as a gatekeeper.\n\n\nWhat is DNS?\n\n\nDomain names are the human-friendly forms of Internet addresses and are commonly used to find websites. The domain name system(DNS) is essentially a global addressing system. It is the way that domain names are located and translated into Internet Protocol (IP) addresses, and vice versa. A domain name such as example.com is a unique alias for an IP address 123.123.123.123, which is an actual physical point on the Internet. The \nInternet Corporation for Assigned Names and Numbers (ICANN)\n is a non-profit organization responsible for coordinating the maintenance and procedures of several databases related to the namespaces of the Internet. We can buy a domain name from a vendor like GoDaddy and others for a period and then tell that domain to point to an actual server address using the websites of those vendors.\n\n\nWhat is a public IP address?\n\n\nA public IP address is an IP address that our home or business router receives from your ISP. Public IP addresses are required for any publicly accessible network devices, like for our home router as well as for the servers that host websites.\n\n\nPublic IP addresses are what differentiate all devices that are plugged into the public internet. Each and every device that\u2019s accessing the internet is using a unique IP address. It\u2019s this address that each Internet Service Provider uses to forward internet requests to a specific home or business.", 
            "title": "Networking"
        }, 
        {
            "location": "/blog/networking-fundamentals/#networking-fundamentals", 
            "text": "", 
            "title": "Networking Fundamentals"
        }, 
        {
            "location": "/blog/networking-fundamentals/#what-is-the-internet", 
            "text": "The internet is a huge network of computing devices communicating with each other based on a pre-agreed set of rules called protocols.   The internet is a global computer network providing a variety of information and communication facilities, consisting of interconnected networks using standardized communication protocols. (google definition)", 
            "title": "What is the internet?"
        }, 
        {
            "location": "/blog/networking-fundamentals/#how-is-this-network-formed-and-how-does-it-work", 
            "text": "The edge devices that are part of this network are called hosts or end systems. For enample: Laptops, mobiles are the end systems. The end systems are connected by a network of communication links and packet switches. The communication links are made up of physical connections made of copper wires, fiber optics, radio spectrum etc. One end system sends data to another by segmenting the data into small segments with header bytes on them. These packages of information are called packets and are sent through the network to the destination end system where they are reassembled into the original data. A packet switch is responsible for routing the packets to its destination. The packet switch takes a packet arriving on one of its incoming communication links and forwards that packet on one of its outgoing communication links. Our router is a packet switch. The sequence of communication links and packet switches traversed by a packet in known as the route through the network.   There is beautiful analogy presented in the book Computer Networking by Kurose and Ross. It says, if a factory needs to move a large amount of cargo to some destination warehouse located thousands of kilometers away, then, the cargo is first segmented and loaded into a fleet of trucks. Each of the trucks then independently travels through the network of highways, roads, and intersections to the destination warehouse. At the destination warehouse, the cargo is unloaded and grouped with the rest of the cargo arriving from the same shipment. Thus, in many ways, packets are analogous to trucks, communication links analogous to highways and roads. Packet switches are analogous to intersections, and end systems are analogous to destination buildings.", 
            "title": "How is this network formed and how does it work?"
        }, 
        {
            "location": "/blog/networking-fundamentals/#what-are-isps-tcpip-and-rfcs", 
            "text": "", 
            "title": "What are ISPs, TCP/IP and RFCs?"
        }, 
        {
            "location": "/blog/networking-fundamentals/#isps", 
            "text": "End systems access the internet through  Internet Service Provider(ISPs) . ISPs include local cable or telephone companies. Each ISPs is in itself a network of packet switches and communication links. These ISPs are also interconnected. Lower-tier ISPs are interconnected through national and international upper-tier ISPs such as AT T and Sprint.", 
            "title": "ISPs"
        }, 
        {
            "location": "/blog/networking-fundamentals/#tcpip", 
            "text": "All the component of this network run protocols that control the sending and receiving of information. A protocol defines the format and the order of the messages exchanged between two or more communicating entities, as well as the actions taken on the transmission and/or receipt of a message or other events. The  Transmission Control Protocol(TCP)  and the  Internet Protocol(IP)  are the two of the most important protocols that are sent and received among the routers and end systems. The internet\u2019s principle protocols are collectively known as TCP/IP.", 
            "title": "TCP/IP"
        }, 
        {
            "location": "/blog/networking-fundamentals/#ieft-and-rfcs", 
            "text": "These protocols are most important for the unanimous functioning and thus important that everyone agrees on what each and every protocol does. These Internet standards are developed by the  Internet Engineering Task Force(IETF) . The IETF standard documents are called  request for comments(RFCs) .", 
            "title": "IEFT and RFCs"
        }, 
        {
            "location": "/blog/networking-fundamentals/#how-does-one-application-running-on-one-end-system-instructs-the-internet-to-deliver-data-to-another-software-running-on-another-end-system", 
            "text": "End systems attached to the Internet, provide an Application Programming Interface(API) that specifies the rules for this process.    Taking an analogy from the same book: Suppose Alice wants to send a letter to Bob using the postal service. Alice, of course, can\u2019t just write the letter(the data) and drop the letter out her window. Instead, the postal service requires that Alice put the letter in an envelope; write Bob\u2019s full name, address, and zip code in the center of the envelope; seal the envelope; put a stamp in the upper-right-hand corner of the envelope; and finally, drop the envelope into an official postal service mailbox. Thus, the postal service has its own \u201cpostal service API\u201d, or set of rules, that Alice must follow to have the postal service deliver her letter to Bob.   In a similar manner, the internet has an API that the software sending data must follow to have the internet deliver the data to the software that will receive the data.", 
            "title": "How does one application running on one end system instructs the Internet to deliver data to another software running on another end system?"
        }, 
        {
            "location": "/blog/networking-fundamentals/#what-are-client-and-server-program-and-p2p-architecture", 
            "text": "A client program is a program running on one end system that requests and receives a service from a server program running on another end system. The web browser is an example of a client program and Nginx or NodeJS or Tomcat is an example of a server program.  Not all Internet application today consists of pure client programs interacting with pure server programs. Increasingly, many application is peer-to-peer(P2P) applications, in which end systems interact and run programs that perform both client and server functions. For example, in P2P file-sharing applications(such as BitTorrent or eMule), the program in the user\u2019s end system act as a client when it requests a file from another peer; and the program acts as a server when it sends a file to another peer.", 
            "title": "What are client and server program and P2P architecture?"
        }, 
        {
            "location": "/blog/networking-fundamentals/#what-are-lan-and-wan", 
            "text": "", 
            "title": "What are LAN and WAN?"
        }, 
        {
            "location": "/blog/networking-fundamentals/#lan", 
            "text": "Local Area Network (LAN)  is a computer network, which is limited to a small office, a single building, multiple buildings inside a campus etc. Typically a LAN is a private network owned and maintained by a single organization.", 
            "title": "LAN"
        }, 
        {
            "location": "/blog/networking-fundamentals/#wan", 
            "text": "A  Wide Area Network (WAN)  spans over multiple geographic locations, which is composed of multiple LANs. ISPs provide the connectivity solutions for WAN.", 
            "title": "WAN"
        }, 
        {
            "location": "/blog/networking-fundamentals/#what-is-an-ip-address", 
            "text": "For one device to communicate with another, it needs an IP address, and it must be unique. If there is another device on the same network with the same IP there will be an IP address conflict and both devices will lose network capability until this is resolved.  The IP address consists of 4 numbers separated by decimals. The IP address itself is separated into a network address and a host address. This means that one part of the IP address identifies the computer network ID and the other part identifies the host ID.\nAs an example, an IP address of 192.168.0.11 with subnet mask 255.255.255.0 uses the first 3 numbers to identify the network and the last number to identify the host. So, the network id would be 192.168.0 and the host id would be 11. Devices can only communicate with other devices on the same network id. In other words, communication will work between 2 devices with IPs 192.168.0.221 and 192.168.0.11 respectively but neither can communicate with 192.168.1.31 because it is part of the 192.168.1 network.  Subnet Mask  : As a general rule wherever there is a 255 in the subnet mask then the corresponding number of the IP address is part of the network id; where there is 0 in the subnet mask the corresponding number in the IP address is part of the host id. For an IP address of 192.168.0.1 with a subnet mask of 255.0.0.0. This tells the device that the first number of the IP address is to be used as the network address and the last 3 are to be used as the host id. In this example, the computer network would be 192.x.x.x. As long as another computer has the same subnet mask and an IP address starting with 192 they can communicate with each other. If the subnet mask was 255.255.0.0 then this means that the first 2 numbers identify the network instead (192.168.x.x). Therefore to be on the same network both devices must have IP addresses starting with 192.168.", 
            "title": "What is an IP address?"
        }, 
        {
            "location": "/blog/networking-fundamentals/#how-do-devices-on-different-networks-communicate", 
            "text": "Communication across different network IDs take place with the help of a router. A router is a network device with 2  network interfaces (NICs) , each being on separate network ids. So, we may have 2 networks; 192.168.1.x and 192.168.2.x. On one NIC the router would have the IP address 192.168.1.1 and on the other, it would have an IP address of 192.168.2.1. Devices on the 192.168.1.x network can now communicate with devices on the 192.168.2.x network via the router.", 
            "title": "How do devices on different networks communicate?"
        }, 
        {
            "location": "/blog/networking-fundamentals/#how-does-the-data-travel-from-source-end-system-to-destination-end-system", 
            "text": "The default gateway is where a network device sends traffic to if it doesn\u2019t know the destination IP address. The default gateway is always a router.\nWhen a network device tries to communicate with another on the same network it sends the data directly to it. If it is on a separate network it forwards the data to whatever IP address is specified in the default gateway. This is because it doesn\u2019t know of this other network and it needs to send the data to a gateway out of its own network. This is why we always put the IP address of the router in the default gateway field. Because a router will be attached to multiple networks, so it knows where these other networks are and it can route traffic to them. Routers also have default gateways so that if they don\u2019t know where the destination is then they can also send the data to its own default gateway. This continues up the IP network hierarchy until it eventually finds a router that is part of the destination network. This last router knows where the destination is and sends it on its way.", 
            "title": "How does the data travel from source end system to destination end system?"
        }, 
        {
            "location": "/blog/networking-fundamentals/#what-is-dhcp", 
            "text": "Network devices need to be configured with an IP address, subnet mask and default gateway that will be unique to that network. Generally, we don\u2019t manually configure them but are configured automatically using DHCP servers. DHCP stands for  Dynamic Host Configuration Protocol . Servers and some routers can be configured to act as a DHCP server. It allots the IP addresses to the connecting devices so to prevent IP address conflicts.", 
            "title": "What is DHCP?"
        }, 
        {
            "location": "/blog/networking-fundamentals/#how-does-a-router-function", 
            "text": "A router should have at least two  network cards (NICs) , one physically connected to one network and the other physically connected to another network. A router can connect any number of networks together providing it has a dedicated NIC for each network.  Routers also learn which are the fastest routes and use them first. Each route the router knows of has a metric value assigned to it. A metric value is basically a preference number. If there are two routes to the same destination then the one with the lowest metric is assumed to be the most efficient. Routers will always use this route first until it fails, in which case it will then try the route with the next lowest metric and so on.  All network devices that use the TCP/IP protocol have a routing table. On Linux based system run netstat -rn command to view this table. All devices use their routing table to determine where to send packets. When a device sends packets to another device, it looks at its routing table to determine the best route possible. If it finds the destination address is \u201con-link\u201d it knows that it is a part of the same subnet as the destination and sends the packets directly to the device. If not it forwards the packet onto whatever is in the gateway field of the matching route entry. This same process is repeated at every router/hop along the way until it eventually arrives at a router that is part of the destination network.", 
            "title": "How does a router function?"
        }, 
        {
            "location": "/blog/networking-fundamentals/#what-is-a-port", 
            "text": "In the internet protocol suite, a port is an endpoint of communication in an operating system, in software, it is a logical construct that identifies a specific process or a type of network service.  A port is always associated with an IP address of a host and the protocol of the communication. A port is identified for each address and protocol by a 16-bit number, commonly known as the port number. For example, an address may be \u201cprotocol: TCP, IP address: 1.2.3.4, port number: 80\u201d, which is written as 1.2.3.4:80 when the protocol is known from context.  The port, which is the number after \u201c:\u201d in the IP address defines the port on which the data has to be sent.By default, HTTP uses port 80 and HTTPS uses port 443, and we don\u2019t add them in the browser but are implicitly handled by the browsers. But a URL like  http://www.example.com:8080/path/  specifies that the web browser connects instead to port 8080 of the HTTP server.", 
            "title": "What is a port?"
        }, 
        {
            "location": "/blog/networking-fundamentals/#what-is-port-forwarding", 
            "text": "Port forwarding or port mapping is an application of  network address translation (NAT)  that redirects a communication request from one address and port number combination to another while the packets are traversing a network gateway, such as a router or firewall. This technique is most commonly used to make services on a host residing on a protected or masqueraded (internal) network available to hosts on the opposite side of the gateway (external network), by remapping the destination IP address and port number of the communication to an internal host.  What this mean is that when a request arrives at a router at a specific port then it reroutes this request to a server in the local network of the router so to be able to process it (if configured on NAT settings). So, it in a way works as a gatekeeper.", 
            "title": "What is port forwarding?"
        }, 
        {
            "location": "/blog/networking-fundamentals/#what-is-dns", 
            "text": "Domain names are the human-friendly forms of Internet addresses and are commonly used to find websites. The domain name system(DNS) is essentially a global addressing system. It is the way that domain names are located and translated into Internet Protocol (IP) addresses, and vice versa. A domain name such as example.com is a unique alias for an IP address 123.123.123.123, which is an actual physical point on the Internet. The  Internet Corporation for Assigned Names and Numbers (ICANN)  is a non-profit organization responsible for coordinating the maintenance and procedures of several databases related to the namespaces of the Internet. We can buy a domain name from a vendor like GoDaddy and others for a period and then tell that domain to point to an actual server address using the websites of those vendors.", 
            "title": "What is DNS?"
        }, 
        {
            "location": "/blog/networking-fundamentals/#what-is-a-public-ip-address", 
            "text": "A public IP address is an IP address that our home or business router receives from your ISP. Public IP addresses are required for any publicly accessible network devices, like for our home router as well as for the servers that host websites.  Public IP addresses are what differentiate all devices that are plugged into the public internet. Each and every device that\u2019s accessing the internet is using a unique IP address. It\u2019s this address that each Internet Service Provider uses to forward internet requests to a specific home or business.", 
            "title": "What is a public IP address?"
        }, 
        {
            "location": "/blog/cloud-computing/", 
            "text": "What is Cloud Computing?\n\n\nCloud computing is the on-demand delivery of compute power, database storage, applications, and other IT resources through a cloud services platform via the internet with pay-as-you-go pricing.\n\n\nCloud Computing Basics\n\n\nWhether you are running applications that share photos to millions of mobile users or you\u2019re supporting the critical operations of your business, a cloud services platform provides rapid access to flexible and low cost IT resources. With cloud computing, you don\u2019t need to make large upfront investments in hardware and spend a lot of time on the heavy lifting of managing that hardware. Instead, you can provision exactly the right type and size of computing resources you need to power your newest bright idea or operate your IT department. You can access as many resources as you need, almost instantly, and only pay for what you use.\n\n\nHow Does Cloud Computing Work?\n\n\nCloud computing provides a simple way to access servers, storage, databases and a broad set of application services over the Internet. A Cloud services platform such as Amazon Web Services owns and maintains the network-connected hardware required for these application services, while you provision and use what you need via a web application.\n\n\nAdvantages of cloud computing\n\n\nTrade capital expense for variable expense\n\n\nInstead of having to invest heavily in data centers and servers before you know how you\u2019re going to use them, you can only pay when you consume computing resources, and only pay for how much you consume.\n\n\nBenefit from massive economies of scale\n\n\nBy using cloud computing, you can achieve a lower variable cost than you can get on your own. Because usage from hundreds of thousands of customers are aggregated in the cloud, providers such as Amazon Web Services can achieve higher economies of scale which translates into lower pay as you go prices.\n\n\nStop guessing capacity\n\n\nEliminate guessing on your infrastructure capacity needs. When you make a capacity decision prior to deploying an application, you often either end up sitting on expensive idle resources or dealing with limited capacity. With cloud computing, these problems go away. You can access as much or as little as you need, and scale up and down as required with only a few minutes notice.\n\n\nIncrease speed and agility\n\n\nIn a cloud computing environment, new IT resources are only ever a click away, which means you reduce the time it takes to make those resources available to your developers from weeks to just minutes. This results in a dramatic increase in agility for the organization, since the cost and time it takes to experiment and develop is significantly lower.\n\n\nStop spending money on running and maintaining data centers\n\n\nFocus on projects that differentiate your business, not the infrastructure. Cloud computing lets you focus on your own customers, rather than on the heavy lifting of racking, stacking and powering servers.\n\n\nGo global in minutes\n\n\nEasily deploy your application in multiple regions around the world with just a few clicks. This means you can provide a lower latency and better experience for your customers simply and at minimal cost.", 
            "title": "Cloud Computing"
        }, 
        {
            "location": "/blog/cloud-computing/#what-is-cloud-computing", 
            "text": "Cloud computing is the on-demand delivery of compute power, database storage, applications, and other IT resources through a cloud services platform via the internet with pay-as-you-go pricing.", 
            "title": "What is Cloud Computing?"
        }, 
        {
            "location": "/blog/cloud-computing/#cloud-computing-basics", 
            "text": "Whether you are running applications that share photos to millions of mobile users or you\u2019re supporting the critical operations of your business, a cloud services platform provides rapid access to flexible and low cost IT resources. With cloud computing, you don\u2019t need to make large upfront investments in hardware and spend a lot of time on the heavy lifting of managing that hardware. Instead, you can provision exactly the right type and size of computing resources you need to power your newest bright idea or operate your IT department. You can access as many resources as you need, almost instantly, and only pay for what you use.", 
            "title": "Cloud Computing Basics"
        }, 
        {
            "location": "/blog/cloud-computing/#how-does-cloud-computing-work", 
            "text": "Cloud computing provides a simple way to access servers, storage, databases and a broad set of application services over the Internet. A Cloud services platform such as Amazon Web Services owns and maintains the network-connected hardware required for these application services, while you provision and use what you need via a web application.", 
            "title": "How Does Cloud Computing Work?"
        }, 
        {
            "location": "/blog/cloud-computing/#advantages-of-cloud-computing", 
            "text": "", 
            "title": "Advantages of cloud computing"
        }, 
        {
            "location": "/blog/cloud-computing/#trade-capital-expense-for-variable-expense", 
            "text": "Instead of having to invest heavily in data centers and servers before you know how you\u2019re going to use them, you can only pay when you consume computing resources, and only pay for how much you consume.", 
            "title": "Trade capital expense for variable expense"
        }, 
        {
            "location": "/blog/cloud-computing/#benefit-from-massive-economies-of-scale", 
            "text": "By using cloud computing, you can achieve a lower variable cost than you can get on your own. Because usage from hundreds of thousands of customers are aggregated in the cloud, providers such as Amazon Web Services can achieve higher economies of scale which translates into lower pay as you go prices.", 
            "title": "Benefit from massive economies of scale"
        }, 
        {
            "location": "/blog/cloud-computing/#stop-guessing-capacity", 
            "text": "Eliminate guessing on your infrastructure capacity needs. When you make a capacity decision prior to deploying an application, you often either end up sitting on expensive idle resources or dealing with limited capacity. With cloud computing, these problems go away. You can access as much or as little as you need, and scale up and down as required with only a few minutes notice.", 
            "title": "Stop guessing capacity"
        }, 
        {
            "location": "/blog/cloud-computing/#increase-speed-and-agility", 
            "text": "In a cloud computing environment, new IT resources are only ever a click away, which means you reduce the time it takes to make those resources available to your developers from weeks to just minutes. This results in a dramatic increase in agility for the organization, since the cost and time it takes to experiment and develop is significantly lower.", 
            "title": "Increase speed and agility"
        }, 
        {
            "location": "/blog/cloud-computing/#stop-spending-money-on-running-and-maintaining-data-centers", 
            "text": "Focus on projects that differentiate your business, not the infrastructure. Cloud computing lets you focus on your own customers, rather than on the heavy lifting of racking, stacking and powering servers.", 
            "title": "Stop spending money on running and maintaining data centers"
        }, 
        {
            "location": "/blog/cloud-computing/#go-global-in-minutes", 
            "text": "Easily deploy your application in multiple regions around the world with just a few clicks. This means you can provide a lower latency and better experience for your customers simply and at minimal cost.", 
            "title": "Go global in minutes"
        }, 
        {
            "location": "/blog/internet-of-things/", 
            "text": "Internet Of Things\n\n\nBroadband Internet is become more widely available, the cost of connecting is decreasing, more devices are being created with Wi-Fi capabilities and sensors built into them, technology costs are going down, and smartphone penetration is sky-rocketing.  All of these things are creating a \"perfect storm\" for the IoT.\n\n\nThe Internet of things (IoT) is the network of physical devices, vehicles, home appliances and other items embedded with electronics, software, sensors, actuators, and connectivity which enables these objects to connect and exchange data. Each thing is uniquely identifiable through its embedded computing system but is able to inter-operate within the existing Internet infrastructure.\n\n\nSimply put, this is the concept of basically connecting any device with an on and off switch to the Internet (and/or to each other). This includes everything from cellphones, coffee makers, washing machines, headphones, lamps, wearable devices and almost anything else you can think of.  This also applies to components of machines, for example a jet engine of an airplane or the drill of an oil rig. As I mentioned, if it has an on and off switch then chances are it can be a part of the IoT.  The analyst firm Gartner says that by 2020 there will be over 26 billion connected devices... That's a lot of connections (some even estimate this number to be much higher, over 100 billion).  The IoT is a giant network of connected \"things\" (which also includes people).  The relationship will be between people-people, people-things, and things-things.", 
            "title": "Internet Of Things"
        }, 
        {
            "location": "/blog/internet-of-things/#internet-of-things", 
            "text": "Broadband Internet is become more widely available, the cost of connecting is decreasing, more devices are being created with Wi-Fi capabilities and sensors built into them, technology costs are going down, and smartphone penetration is sky-rocketing.  All of these things are creating a \"perfect storm\" for the IoT.  The Internet of things (IoT) is the network of physical devices, vehicles, home appliances and other items embedded with electronics, software, sensors, actuators, and connectivity which enables these objects to connect and exchange data. Each thing is uniquely identifiable through its embedded computing system but is able to inter-operate within the existing Internet infrastructure.  Simply put, this is the concept of basically connecting any device with an on and off switch to the Internet (and/or to each other). This includes everything from cellphones, coffee makers, washing machines, headphones, lamps, wearable devices and almost anything else you can think of.  This also applies to components of machines, for example a jet engine of an airplane or the drill of an oil rig. As I mentioned, if it has an on and off switch then chances are it can be a part of the IoT.  The analyst firm Gartner says that by 2020 there will be over 26 billion connected devices... That's a lot of connections (some even estimate this number to be much higher, over 100 billion).  The IoT is a giant network of connected \"things\" (which also includes people).  The relationship will be between people-people, people-things, and things-things.", 
            "title": "Internet Of Things"
        }, 
        {
            "location": "/blog/understanding-iaas-paas-saas/", 
            "text": "Understanding IAAS, PAAS and SAAS\n\n\nInfrastructure As A Service\n\n\nInfrastructure as a service (IaaS) is an instant computing infrastructure, provisioned and managed over the Internet. Quickly scale up and down with demand, and pay only for what you use.\n\n\nIaaS helps you avoid the expense and complexity of buying and managing your own physical servers and other datacenter infrastructure. Each resource is offered as a separate service component, and you only need to rent a particular one for as long as you need it. The cloud computing service provider manages the infrastructure, while you purchase, install, configure, and manage your own software\u2014operating systems, middleware, and applications.\n\n\n\n\nPlatform As A Service\n\n\nPlatform as a service (PaaS) is a complete development and deployment environment in the cloud, with resources that enable you to deliver everything from simple cloud-based apps to sophisticated, cloud-enabled enterprise applications. You purchase the resources you need from a cloud service provider on a pay-as-you-go basis and access them over a secure Internet connection.\n\n\nLike IaaS, PaaS includes infrastructure\u2014servers, storage, and networking\u2014but also middleware, development tools, business intelligence (BI) services, database management systems, and more. PaaS is designed to support the complete web application lifecycle: building, testing, deploying, managing, and updating.\n\n\nPaaS allows you to avoid the expense and complexity of buying and managing software licenses, the underlying application infrastructure and middleware or the development tools and other resources. You manage the applications and services you develop, and the cloud service provider typically manages everything else.\n\n\nSoftware As A Service\n\n\nSoftware as a service (SaaS) allows users to connect to and use cloud-based apps over the Internet. Common examples are email, calendaring, and office tools (such as Microsoft Office 365).\n\n\nSaaS provides a complete software solution that you purchase on a pay-as-you-go basis from a cloud service provider. You rent the use of an app for your organization, and your users connect to it over the Internet, usually with a web browser. All of the underlying infrastructure, middleware, app software, and app data are located in the service provider\u2019s data center. The service provider manages the hardware and software, and with the appropriate service agreement, will ensure the availability and the security of the app and your data as well. SaaS allows your organization to get quickly up and running with an app at minimal upfront cost.\n\n\n\n\nReferences\n\n\n\n\nMicrosoft Azure documentation\n\n\nIBM cloud learn", 
            "title": "IAAS, PAAS and SAAS"
        }, 
        {
            "location": "/blog/understanding-iaas-paas-saas/#understanding-iaas-paas-and-saas", 
            "text": "", 
            "title": "Understanding IAAS, PAAS and SAAS"
        }, 
        {
            "location": "/blog/understanding-iaas-paas-saas/#infrastructure-as-a-service", 
            "text": "Infrastructure as a service (IaaS) is an instant computing infrastructure, provisioned and managed over the Internet. Quickly scale up and down with demand, and pay only for what you use.  IaaS helps you avoid the expense and complexity of buying and managing your own physical servers and other datacenter infrastructure. Each resource is offered as a separate service component, and you only need to rent a particular one for as long as you need it. The cloud computing service provider manages the infrastructure, while you purchase, install, configure, and manage your own software\u2014operating systems, middleware, and applications.", 
            "title": "Infrastructure As A Service"
        }, 
        {
            "location": "/blog/understanding-iaas-paas-saas/#platform-as-a-service", 
            "text": "Platform as a service (PaaS) is a complete development and deployment environment in the cloud, with resources that enable you to deliver everything from simple cloud-based apps to sophisticated, cloud-enabled enterprise applications. You purchase the resources you need from a cloud service provider on a pay-as-you-go basis and access them over a secure Internet connection.  Like IaaS, PaaS includes infrastructure\u2014servers, storage, and networking\u2014but also middleware, development tools, business intelligence (BI) services, database management systems, and more. PaaS is designed to support the complete web application lifecycle: building, testing, deploying, managing, and updating.  PaaS allows you to avoid the expense and complexity of buying and managing software licenses, the underlying application infrastructure and middleware or the development tools and other resources. You manage the applications and services you develop, and the cloud service provider typically manages everything else.", 
            "title": "Platform As A Service"
        }, 
        {
            "location": "/blog/understanding-iaas-paas-saas/#software-as-a-service", 
            "text": "Software as a service (SaaS) allows users to connect to and use cloud-based apps over the Internet. Common examples are email, calendaring, and office tools (such as Microsoft Office 365).  SaaS provides a complete software solution that you purchase on a pay-as-you-go basis from a cloud service provider. You rent the use of an app for your organization, and your users connect to it over the Internet, usually with a web browser. All of the underlying infrastructure, middleware, app software, and app data are located in the service provider\u2019s data center. The service provider manages the hardware and software, and with the appropriate service agreement, will ensure the availability and the security of the app and your data as well. SaaS allows your organization to get quickly up and running with an app at minimal upfront cost.", 
            "title": "Software As A Service"
        }, 
        {
            "location": "/blog/understanding-iaas-paas-saas/#references", 
            "text": "Microsoft Azure documentation  IBM cloud learn", 
            "title": "References"
        }, 
        {
            "location": "/tools/openldap/", 
            "text": "OpenLDAP\n\n\nOpenLDAP is a opensource implementation of Lightweight Directory Access Protocol (LDAP).\n\n\nTable of contents\n\n\n\n\nInstallation\n\n\nConfiguration\n\n\nFAQ's\n\n\n\n\nReferences\n\n\n\n\nOpenldap\n\n\nZytrax\n\n\nInstalling BDB on Linux - The Ecommerce Blog", 
            "title": "Introduction"
        }, 
        {
            "location": "/tools/openldap/#openldap", 
            "text": "OpenLDAP is a opensource implementation of Lightweight Directory Access Protocol (LDAP).", 
            "title": "OpenLDAP"
        }, 
        {
            "location": "/tools/openldap/#table-of-contents", 
            "text": "Installation  Configuration  FAQ's", 
            "title": "Table of contents"
        }, 
        {
            "location": "/tools/openldap/#references", 
            "text": "Openldap  Zytrax  Installing BDB on Linux - The Ecommerce Blog", 
            "title": "References"
        }, 
        {
            "location": "/tools/openldap/install/", 
            "text": "Installing OpenLDAP server\n\n\nOpenLDAP has a dependency on Oracle's Berkeley DB hence we need to first install berkeley db.\n\n\nPrerequisite\n\n\nMake sure gcc, gcc-c++, make and other required packages are available on the server.\n\n\nRun the below command : to confirm and if not available install them.\n\n\n1\n2\nyum update -y \n\\\n\nyum install unzip gcc gcc-c++ make -y groff\n\n\n\n\n\n\nInstalling Berkeley Db\n\n\nCopy paste the below code into a shell script and execute it. Change the BDB_VERSION variable if you want to install a different version.\n\n\n1\n2\n3\n4\n5\n6\n7\nBDB_VERSION\n=\n4.8.30\n\ncurl -o db-\n${\nBDB_VERSION\n}\n.zip -fSL http://download.oracle.com/berkeley-db/db-\n${\nBDB_VERSION\n}\n.zip \n\\\n\nunzip db-\n${\nBDB_VERSION\n}\n.zip \n\\\n\n\ncd\n ./db-\n${\nBDB_VERSION\n}\n/build_unix \n\\\n\n../dist/configure --enable-cxx \n\\\n\nmake \n\\\n\nmake install\n\n\n\n\n\n\nInstalling OpenLDAP\n\n\nExport below env variable\n\n\n1\n2\n3\nexport\n \nCPPFLAGS\n=\n-I/usr/local/BerkeleyDB.4.8/include\n\n\nexport\n \nLDFLAGS\n=\n-L/usr/local/BerkeleyDB.4.8/lib\n\n\nexport\n \nLD_LIBRARY_PATH\n=\n/usr/local/BerkeleyDB.4.8/lib/\n\n\n\n\n\n\n\nCopy paste the below code into a shell script and execute it. Change the INSTALL_PATH if you wish to install in another path and OPENLDAP_VERSION if you want to install a different version. Make sure that the OpenLDAP version and the Berkeley Db version are compatible.\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\nINSTALL_PATH\n=\n/opt/openldap\n\n\nOPENLDAP_VERSION\n=\n2.4.45\n\n\ncurl -o openldap-\n${\nOPENLDAP_VERSION\n}\n.tgz -fSL https://www.openldap.org/software/download/OpenLDAP/openldap-release/openldap-\n${\nOPENLDAP_VERSION\n}\n.tgz \n\\\n\ntar -xzvf openldap-\n${\nOPENLDAP_VERSION\n}\n.tgz \n\\\n\nls -lrt \n\\\n\n./openldap-\n${\nOPENLDAP_VERSION\n}\n/configure --prefix\n=\n${\nINSTALL_PATH\n}\n \n\\\n\n    --enable-slapd \n\\\n\n    --enable-bdb \n\\\n\n    --enable-overlays \n\\\n\n    --enable-syslog \n\\\n\n    --enable-accesslog \n\\\n\n    --enable-auditlog \n\\\n\n    --enable-dynlist \n\\\n\n    --enable-ppolicy \n\\\n\n    --enable-memberof \n\\\n\n    --enable-constraint \n\\\n\n    --enable-debug \n\\\n\nmake depend \n\\\n\nmake \n\\\n\nmake install", 
            "title": "Installation"
        }, 
        {
            "location": "/tools/openldap/install/#installing-openldap-server", 
            "text": "OpenLDAP has a dependency on Oracle's Berkeley DB hence we need to first install berkeley db.", 
            "title": "Installing OpenLDAP server"
        }, 
        {
            "location": "/tools/openldap/install/#prerequisite", 
            "text": "Make sure gcc, gcc-c++, make and other required packages are available on the server.  Run the below command : to confirm and if not available install them.  1\n2 yum update -y  \\ \nyum install unzip gcc gcc-c++ make -y groff", 
            "title": "Prerequisite"
        }, 
        {
            "location": "/tools/openldap/install/#installing-berkeley-db", 
            "text": "Copy paste the below code into a shell script and execute it. Change the BDB_VERSION variable if you want to install a different version.  1\n2\n3\n4\n5\n6\n7 BDB_VERSION = 4.8.30 \ncurl -o db- ${ BDB_VERSION } .zip -fSL http://download.oracle.com/berkeley-db/db- ${ BDB_VERSION } .zip  \\ \nunzip db- ${ BDB_VERSION } .zip  \\  cd  ./db- ${ BDB_VERSION } /build_unix  \\ \n../dist/configure --enable-cxx  \\ \nmake  \\ \nmake install", 
            "title": "Installing Berkeley Db"
        }, 
        {
            "location": "/tools/openldap/install/#installing-openldap", 
            "text": "Export below env variable  1\n2\n3 export   CPPFLAGS = -I/usr/local/BerkeleyDB.4.8/include  export   LDFLAGS = -L/usr/local/BerkeleyDB.4.8/lib  export   LD_LIBRARY_PATH = /usr/local/BerkeleyDB.4.8/lib/    Copy paste the below code into a shell script and execute it. Change the INSTALL_PATH if you wish to install in another path and OPENLDAP_VERSION if you want to install a different version. Make sure that the OpenLDAP version and the Berkeley Db version are compatible.   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21 INSTALL_PATH = /opt/openldap  OPENLDAP_VERSION = 2.4.45 \n\ncurl -o openldap- ${ OPENLDAP_VERSION } .tgz -fSL https://www.openldap.org/software/download/OpenLDAP/openldap-release/openldap- ${ OPENLDAP_VERSION } .tgz  \\ \ntar -xzvf openldap- ${ OPENLDAP_VERSION } .tgz  \\ \nls -lrt  \\ \n./openldap- ${ OPENLDAP_VERSION } /configure --prefix = ${ INSTALL_PATH }   \\ \n    --enable-slapd  \\ \n    --enable-bdb  \\ \n    --enable-overlays  \\ \n    --enable-syslog  \\ \n    --enable-accesslog  \\ \n    --enable-auditlog  \\ \n    --enable-dynlist  \\ \n    --enable-ppolicy  \\ \n    --enable-memberof  \\ \n    --enable-constraint  \\ \n    --enable-debug  \\ \nmake depend  \\ \nmake  \\ \nmake install", 
            "title": "Installing OpenLDAP"
        }, 
        {
            "location": "/tools/openldap/config/", 
            "text": "Configuring OpenLDAP server\n\n\nslapd.conf file\n\n\nslapd.conf file holds all the configuration required for running the openLDAP server. Below is a example of the slapd.conf file.\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n###### PrivateSquare.in slapd config file ############\n\n\n#\n\n\n# NOTES: inetorgperson picks up attributes and objectclasses\n\n\n#        from all three schemas\n\n\n#\n\ninclude         /opt/openldap/etc/openldap/schema/core.schema\ninclude         /opt/openldap/etc/openldap/schema/cosine.schema\ninclude         /opt/openldap/etc/openldap/schema/inetorgperson.schema\ninclude         /opt/openldap/etc/openldap/schema/dyngroup.schema\n\n\n# NO SECURITY - no access clause\n\n\n# defaults to anonymous access for read\n\n\n# only rootdn can write\n\n\n\n#access to *\n\n\n# by anonymous none\n\n\n# by * write\n\n\n\n# NO REFERRALS\n\n\n\n# DON\nT bother with ARGS file unless you feel strongly\n\n\n# slapd scripts stop scripts need this to work\n\npidfile     /opt/openldap/run/slapd.pid\nargsfile    /opt/openldap/run/slapd.args\n\n\n# enable a lot of logging - we might need it\n\n\n# but generates huge logs\n\nloglevel        -1\n\n\n# NO TLS-enabled connections\n\n\n\n####################################################################\n\n\n### Create configuration DIT in OpenLdap\n\n\n###\n\n\n### NOTE: the suffix is hardcoded as cn=config and\n\n\n### MUST not have a suffix directive\n\n\n### normal rules apply - rootdn can be anything you want\n\n\n### but MUST be under cn=config\n\n\n#######################################################################\n\ndatabase config\nrootdn \ncn=root,cn=config\n\nrootpw \n{\nSSHA\n}\nGT4+O2DLvYfJTqAM7VFIGCiY+Q+fGcgr\n\n\n# Private Square database -----------------------------\n\n\ndatabase bdb\nsuffix \ndc=privatesquare,dc=in\n\n\noverlay dynlist\ndynlist-attrset groupOfURLs memberURL owner\n\n\n# root or superuser\n\nrootdn \ncn=root,dc=privatesquare,dc=in\n\nrootpw \n{\nSSHA\n}\nGT4+O2DLvYfJTqAM7VFIGCiY+Q+fGcgr\n\n# # The database directory MUST exist prior to running slapd AND\n\n\n# # change path as necessary\n\ndirectory       /data/openldap\n\nindex   objectClass     eq\nindex   uid     eq\nindex   cn,gn,mail eq,sub\nindex sn eq,sub\nindex ou eq\n\ncachesize \n10000\n\ncheckpoint \n128\n \n15\n\n\n\n\n\n\n\n/opt/openldap is the install path of openLDAP and /data/openldap is the data path for the private square db.\n\n\nBuilding the Config Db\n\n\nBelow command builds the config db based on the entries in the slapd.conf file. The config db will be built into the path ${INSTALL_PATH}/etc/openldap/slapd.d\n\n\n1\n2\ncd\n \n${\nINSTALL_PATH\n}\n\n./sbin/slaptest -f ./etc/openldap/slapd.conf -F ./etc/openldap/slapd.d -u\n\n\n\n\n\n\nBuilding the Data Db\n\n\nFor building the data db you need to import the initial LDAP structure you prefer.\n\n\nThis is the entry I need for the private squate db.\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n# Initial root entry for privatesquare.in\n\ndn: dc=privatesquare,dc=in\nobjectClass: top\nobjectClass: domain\ndc: privatesquare\n\ndn: ou=users,dc=privatesquare,dc=in\nobjectClass: top\nobjectClass: organizationalUnit\nou: users\n\ndn: ou=groups,dc=privatesquare,dc=in\nobjectClass: top\nobjectClass: organizationalUnit\nou: groups\n\n\n\n\n\n\ntouch the contents of the ldif into a initial.ldif file and run the below command to build the data db.\n\n\n1\n2\ncd\n \n${\nINSTALL_PATH\n}\n\n./sbin/slapadd -q -l \n[\nPath to the initail ldif file\n]\n -f ./etc/openldap/slapd.conf\n\n\n\n\n\n\nTesting the configuration\n\n\nTest the configuration by running the below command.\n\n\n1\n2\ncd\n \n${\nINSTALL_PATH\n}\n\n./sbin/slaptest -f ./etc/openldap/slapd.conf -F ./etc/openldap/slapd.d\n\n\n\n\n\n\nStart OpenLDAP\n\n\n1\n2\ncd\n \n${\nINSTALL_PATH\n}\n\n./libexec/slapd -h \nldap://hostname:port\n  -f ./etc/openldap/slapd.conf", 
            "title": "Configuration"
        }, 
        {
            "location": "/tools/openldap/config/#configuring-openldap-server", 
            "text": "", 
            "title": "Configuring OpenLDAP server"
        }, 
        {
            "location": "/tools/openldap/config/#slapdconf-file", 
            "text": "slapd.conf file holds all the configuration required for running the openLDAP server. Below is a example of the slapd.conf file.   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66 ###### PrivateSquare.in slapd config file ############  #  # NOTES: inetorgperson picks up attributes and objectclasses  #        from all three schemas  # \ninclude         /opt/openldap/etc/openldap/schema/core.schema\ninclude         /opt/openldap/etc/openldap/schema/cosine.schema\ninclude         /opt/openldap/etc/openldap/schema/inetorgperson.schema\ninclude         /opt/openldap/etc/openldap/schema/dyngroup.schema # NO SECURITY - no access clause  # defaults to anonymous access for read  # only rootdn can write  #access to *  # by anonymous none  # by * write  # NO REFERRALS  # DON T bother with ARGS file unless you feel strongly  # slapd scripts stop scripts need this to work \npidfile     /opt/openldap/run/slapd.pid\nargsfile    /opt/openldap/run/slapd.args # enable a lot of logging - we might need it  # but generates huge logs \nloglevel        -1 # NO TLS-enabled connections  ####################################################################  ### Create configuration DIT in OpenLdap  ###  ### NOTE: the suffix is hardcoded as cn=config and  ### MUST not have a suffix directive  ### normal rules apply - rootdn can be anything you want  ### but MUST be under cn=config  ####################################################################### \ndatabase config\nrootdn  cn=root,cn=config \nrootpw  { SSHA } GT4+O2DLvYfJTqAM7VFIGCiY+Q+fGcgr # Private Square database ----------------------------- \n\ndatabase bdb\nsuffix  dc=privatesquare,dc=in \n\noverlay dynlist\ndynlist-attrset groupOfURLs memberURL owner # root or superuser \nrootdn  cn=root,dc=privatesquare,dc=in \nrootpw  { SSHA } GT4+O2DLvYfJTqAM7VFIGCiY+Q+fGcgr # # The database directory MUST exist prior to running slapd AND  # # change path as necessary \ndirectory       /data/openldap\n\nindex   objectClass     eq\nindex   uid     eq\nindex   cn,gn,mail eq,sub\nindex sn eq,sub\nindex ou eq\n\ncachesize  10000 \ncheckpoint  128   15    /opt/openldap is the install path of openLDAP and /data/openldap is the data path for the private square db.", 
            "title": "slapd.conf file"
        }, 
        {
            "location": "/tools/openldap/config/#building-the-config-db", 
            "text": "Below command builds the config db based on the entries in the slapd.conf file. The config db will be built into the path ${INSTALL_PATH}/etc/openldap/slapd.d  1\n2 cd   ${ INSTALL_PATH } \n./sbin/slaptest -f ./etc/openldap/slapd.conf -F ./etc/openldap/slapd.d -u", 
            "title": "Building the Config Db"
        }, 
        {
            "location": "/tools/openldap/config/#building-the-data-db", 
            "text": "For building the data db you need to import the initial LDAP structure you prefer.  This is the entry I need for the private squate db.   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16 # Initial root entry for privatesquare.in\n\ndn: dc=privatesquare,dc=in\nobjectClass: top\nobjectClass: domain\ndc: privatesquare\n\ndn: ou=users,dc=privatesquare,dc=in\nobjectClass: top\nobjectClass: organizationalUnit\nou: users\n\ndn: ou=groups,dc=privatesquare,dc=in\nobjectClass: top\nobjectClass: organizationalUnit\nou: groups   touch the contents of the ldif into a initial.ldif file and run the below command to build the data db.  1\n2 cd   ${ INSTALL_PATH } \n./sbin/slapadd -q -l  [ Path to the initail ldif file ]  -f ./etc/openldap/slapd.conf", 
            "title": "Building the Data Db"
        }, 
        {
            "location": "/tools/openldap/config/#testing-the-configuration", 
            "text": "Test the configuration by running the below command.  1\n2 cd   ${ INSTALL_PATH } \n./sbin/slaptest -f ./etc/openldap/slapd.conf -F ./etc/openldap/slapd.d", 
            "title": "Testing the configuration"
        }, 
        {
            "location": "/tools/openldap/config/#start-openldap", 
            "text": "1\n2 cd   ${ INSTALL_PATH } \n./libexec/slapd -h  ldap://hostname:port   -f ./etc/openldap/slapd.conf", 
            "title": "Start OpenLDAP"
        }, 
        {
            "location": "/tools/openldap/ldap-server-error-codes/", 
            "text": "Server-Side Error Codes\n\n\nVarious LDAP specifications define a number of common result codes that may be included in responses to clients. These result codes include (but are not necessarily limited to):\n\n\n0: Success\n\n\nThis indicates that the operation completed successfully. It may be returned in response to an add, bind, delete, extended, modify, modify DN, or search operations.\n\n\nCompare operations will not return a success result. If a compare operation does not encounter an error during processing, then the server should return a result of either \"compare true\" or \"compare false\", based on whether the target entry had the specified attribute value.\n\n\n1: Operations Error\n\n\nThis is intended to indicate that the client has requested an operation at an inappropriate time or in an incorrect order. For example, it may be used if a client sends a non-bind request in the middle of a multi-stage bind operation.\n\n\nNote that some directory servers use this as a generic \"server error\" type result. This is not the intended use for this result code (the \"other\" result is a better choice for this), but clients may need to be aware of this possibility.\n\n\n2: Protocol Error\n\n\nThis generally indicates that the client request was improperly formatted in some way. For a bind operation, it may indicate that the client attempted to use an unsupported LDAP protocol version. For an extended operation, it may indicate that the server does not support the extended request type.\n\n\nNote that this result code can only be used if the server is able to at least partially decode the request in order to determine the message ID and operation type, since the server needs that information in order to craft an appropriate response.\n\n\n3: Time Limit Exceeded\n\n\nThis indicates that a search operation took longer to complete than allowed by the maximum time limit for that operation. This may be the time limit specified by the client in the search request, or it may be a time limit imposed by the server.\n\n\n4: Size Limit Exceeded\n\n\nThis indicates that a search operation would have returned more entries than were allowed for that operation. This may be the size limit specified by the client in the search request, or it may be a size limit imposed by the server. Note that the server may return a portion of the matching entries before this result.\n\n\n5: Compare False\n\n\nThis indicates that a compare operation was processed successfully but that the target entry did not match the provided attribute value assertion.\n\n\n6: Compare True\n\n\nThis indicates that a compare operation was processed successfully and that the target entry matched the provided attribute value assertion.\n\n\n7: Authentication Method Not Supported\n\n\nThis indicates that a bind operation failed because the server does not support the requested authentication type.\n\n\n8: Stronger Authentication Required\n\n\nThis indicates that the server requires that the client be authenticated with a stronger mechanism than has previously been performed in order to process the request.\n\n\nThis result code may be used in a notice of disconnection unsolicited notification if the server believes that the security of the connection has been compromised.\n\n\n10: Referral\n\n\nThis indicates that the server could not process the requested operation, but that it may succeed if attempted in another location, as specified by the referral URIs included in the response.\n\n\n11: Administrative Limit Exceeded\n\n\nThis indicates that an administrative limit was exceeded while processing the request. For example, some directory servers use this response to indicate that it would have required examining too many entries to process the request.\n\n\n12: Unavailable Critical Extension\n\n\nThis indicates that the request included a critical control that was not recognized or could not be processed.\n\n\n13: Confidentiality Required\n\n\nThis indicates that the requested operation is only allowed over a secure connection.\n\n\n14: SASL Bind in Progress\n\n\nThis indicates that the server requires more information from the client in order to complete the SASL bind operation. In such responses, the \"server SASL credentials\" element of the result message will often include information the client needs for subsequent phases of bind processing.\n\n\n16: No Such Attribute\n\n\nThis indicates that the client attempted to interact with an attribute that does not exist in the target entry (e.g., to remove an attribute or value that does not exist).\n\n\n17: Undefined Attribute Type\n\n\nThis indicates that the client request included an attribute type that is not defined in the server schema.\n\n\n18: Inappropriate Matching\n\n\nThis indicates that the client request attempted to perform an unsupported type of matching against an attribute. For example, this may be used if the attribute type does not have an appropriate matching rule for the type of matching requested for that attribute.\n\n\n19: Constraint Violation\n\n\nThis indicates that the client request would have caused the server to violate some constraint defined in the server (e.g., to add more than one value to a single-valued attribute).\n\n\n20: Attribute or Value Exists\n\n\nThis indicates that the client request attempted to add an attribute or value to an entry that already contained that attribute or value.\n\n\n21: Invalid Attribute Syntax\n\n\nThis indicates that the client request would have resulted in an attribute value that did not conform to the syntax for that attribute type.\n\n\n32: No Such Object\n\n\nThis indicates that the client request targeted an entry that does not exist. Note that some servers use this result for a bind request that targets a nonexistent user, even though \"invalid credentials\" is a more appropriate result for that case.\n\n\n33: Alias Problem\n\n\nThis indicates that a problem was encountered while interacting with an alias entry (e.g., the alias refers to an entry that does not exist).\n\n\n34: Invalid DN Syntax\n\n\nThis indicates that the request included a malformed or invalid DN or RDN.\n\n\n36: Alias Dereferencing Problem\n\n\nThis indicates that the client attempted to interact with an alias entry in a manner that was not allowed (e.g., for an operation that does not allow the use of aliases, or if the client does not have permission to access the entry referenced by the alias).\n\n\n48: Inappropriate Authentication\n\n\nThis indicates that the client attempted to perform a type of authentication that is not allowed for the target user (e.g., because the user does not have the necessary credentials for that type of authentication). This may also indicate that the client attempted to perform anonymous authentication when that is not allowed.\n\n\n49: Invalid Credentials\n\n\nThis indicates that the client attempted to bind as a user that does not exist, attempted to bind as a user that is not allowed to bind (e.g., because it has expired, because it has been locked because of too many failed authentication attempts, etc.), or attempted to bind with credentials that were not correct for the target user.\n\n\n50: Insufficient Access Rights\n\n\nThis indicates that the client does not have permission to perform the requested operation.\n\n\n51: Busy\n\n\nThis indicates that the server is currently too busy to process the requested operation.\n\n\n52: Unavailable\n\n\nThis indicates that the server is currently unavailable (e.g., because it is being shut down or is in a maintenance state).\n\n\n53: Unwilling to Perform\n\n\nThis indicates that the server is unwilling to process the requested operation for some reason.\n\n\n54: Loop Detected\n\n\nThis indicates that the server has detected an internal loop while processing the requested operation (e.g., if two alias entries reference each other).\n\n\n60: Sort Control Missing\n\n\nThis indicates that the search request included a virtual list view request control without also including the required server-side sort request control.\n\n\n61: Offset Range Error\n\n\nThis indicates that the search request included a virtual list view request control with an invalid offset or content count.\n\n\n64: Naming Violation\n\n\nThis indicates that the requested add or modify DN operation would have resulted in an entry that violates server naming restrictions (e.g., as might be imposed by a name form defined in the server schema).\n\n\n65: Object Class Violation\n\n\nThis indicates that the requested operation would have resulted in an entry that violates schema restrictions imposed by its object classes (e.g., to include an attribute that is not allowed to be present in the entry, or to omit an attribute that is required to be present in the entry).\n\n\n66: Not Allowed on Non-Leaf Entry\n\n\nThis indicates that the requested operation cannot be performed against an entry that has one or more subordinate entries. For example, a delete operation is normally not allowed to remove an entry that has one or more subordinates.\n\n\n67: Not Allowed on RDN\n\n\nThis indicates that the requested operation is not allowed because it would have altered the entry to remove an attribute value used in the entry's RDN.\n\n\n68: Entry Already Exists\n\n\nThis indicates that the requested add or modify DN operation could not be processed because another entry already exists with the DN that would have resulted from that operation.\n\n\n69: Object Class Modifications Prohibited\n\n\nThis indicates that the requested operation would have resulted in a disallowed change to the object classes contained in the entry (e.g., the operation would have changed the entry's structural object class).\n\n\n71: Affects Multiple DSAs\n\n\nThis indicates that the requested operation could not be processed because it would have required interacting with data in multiple directory server instances in a way that is not supported.\n\n\n76: Virtual List View Error\n\n\nThis indicates that a search operation failed because of processing associated with a virtual list view request control included in the request (e.g., if a necessary index was not in place to facilitate the virtual list view processing).\n\n\n80: Other\n\n\nThis indicates that some problem was encountered during processing that is not covered by any of the other defined result codes (e.g., a server error).\n\n\n118: Canceled\n\n\nThis indicates that an operation was canceled through the use of the cancel extended request. If an operation is canceled in this way, then this result code will be used for both the operation that was canceled and for the cancel extended operation itself.\n\n\n119: No Such Operation\n\n\nThis indicates that an attempt to cancel an operation via the cancel extended request was not successful because the server did not have any knowledge of the target operation. This often means that the server had already completed processing for the operation by the time it received and attempted to process the cancel request.\n\n\n120: Too Late\n\n\nThis indicates that an attempt to cancel an operation via the cancel extended request was not successful because processing for that operation had already reached a point beyond which it could be canceled.\n\n\n121: Cannot Cancel\n\n\nThis indicates that an attempt to cancel an operation via the cancel extended request was not successful because the target operation is not an operation that can be canceled. Operations that cannot be canceled include abandon, bind, unbind, and the cancel and StartTLS extended operations.\n\n\n122: Assertion Failed\n\n\nThis indicates that the requested operation could not be processed because the request included an LDAP assertion request control, but the assertion filter did not match the target entry.\n\n\n123: Authorization Denied\n\n\nThis indicates that the requested operation could not be processed because the request included a proxied authorization request control (or some similar control intended to specify an alternate authorization identity for the operation), but the client was not allowed to request the use of that alternate authorization identity.\n\n\n4096: Synchronization Refresh Required\n\n\nThis indicates that an attempt to use the content synchronization request control in order to perform an incremental update failed for some reason and the client will instead need to request an initial content.\n\n\n16654: No Operation\n\n\nThis indicates that the associated operation would likely have succeeded, to the extent that the server was able to make the determination, but was not actually processed because the request included the LDAP no operation control. Note that at present, the numeric value for this result code is not an official standard because the specification for the no operation request control has not progressed far enough to be assigned an official numeric value, but the value 16654 is in common use by a number of servers for this purpose.", 
            "title": "Server Error Codes"
        }, 
        {
            "location": "/tools/openldap/ldap-server-error-codes/#server-side-error-codes", 
            "text": "Various LDAP specifications define a number of common result codes that may be included in responses to clients. These result codes include (but are not necessarily limited to):", 
            "title": "Server-Side Error Codes"
        }, 
        {
            "location": "/tools/openldap/ldap-server-error-codes/#0-success", 
            "text": "This indicates that the operation completed successfully. It may be returned in response to an add, bind, delete, extended, modify, modify DN, or search operations.  Compare operations will not return a success result. If a compare operation does not encounter an error during processing, then the server should return a result of either \"compare true\" or \"compare false\", based on whether the target entry had the specified attribute value.", 
            "title": "0: Success"
        }, 
        {
            "location": "/tools/openldap/ldap-server-error-codes/#1-operations-error", 
            "text": "This is intended to indicate that the client has requested an operation at an inappropriate time or in an incorrect order. For example, it may be used if a client sends a non-bind request in the middle of a multi-stage bind operation.  Note that some directory servers use this as a generic \"server error\" type result. This is not the intended use for this result code (the \"other\" result is a better choice for this), but clients may need to be aware of this possibility.", 
            "title": "1: Operations Error"
        }, 
        {
            "location": "/tools/openldap/ldap-server-error-codes/#2-protocol-error", 
            "text": "This generally indicates that the client request was improperly formatted in some way. For a bind operation, it may indicate that the client attempted to use an unsupported LDAP protocol version. For an extended operation, it may indicate that the server does not support the extended request type.  Note that this result code can only be used if the server is able to at least partially decode the request in order to determine the message ID and operation type, since the server needs that information in order to craft an appropriate response.", 
            "title": "2: Protocol Error"
        }, 
        {
            "location": "/tools/openldap/ldap-server-error-codes/#3-time-limit-exceeded", 
            "text": "This indicates that a search operation took longer to complete than allowed by the maximum time limit for that operation. This may be the time limit specified by the client in the search request, or it may be a time limit imposed by the server.", 
            "title": "3: Time Limit Exceeded"
        }, 
        {
            "location": "/tools/openldap/ldap-server-error-codes/#4-size-limit-exceeded", 
            "text": "This indicates that a search operation would have returned more entries than were allowed for that operation. This may be the size limit specified by the client in the search request, or it may be a size limit imposed by the server. Note that the server may return a portion of the matching entries before this result.", 
            "title": "4: Size Limit Exceeded"
        }, 
        {
            "location": "/tools/openldap/ldap-server-error-codes/#5-compare-false", 
            "text": "This indicates that a compare operation was processed successfully but that the target entry did not match the provided attribute value assertion.", 
            "title": "5: Compare False"
        }, 
        {
            "location": "/tools/openldap/ldap-server-error-codes/#6-compare-true", 
            "text": "This indicates that a compare operation was processed successfully and that the target entry matched the provided attribute value assertion.", 
            "title": "6: Compare True"
        }, 
        {
            "location": "/tools/openldap/ldap-server-error-codes/#7-authentication-method-not-supported", 
            "text": "This indicates that a bind operation failed because the server does not support the requested authentication type.", 
            "title": "7: Authentication Method Not Supported"
        }, 
        {
            "location": "/tools/openldap/ldap-server-error-codes/#8-stronger-authentication-required", 
            "text": "This indicates that the server requires that the client be authenticated with a stronger mechanism than has previously been performed in order to process the request.  This result code may be used in a notice of disconnection unsolicited notification if the server believes that the security of the connection has been compromised.", 
            "title": "8: Stronger Authentication Required"
        }, 
        {
            "location": "/tools/openldap/ldap-server-error-codes/#10-referral", 
            "text": "This indicates that the server could not process the requested operation, but that it may succeed if attempted in another location, as specified by the referral URIs included in the response.", 
            "title": "10: Referral"
        }, 
        {
            "location": "/tools/openldap/ldap-server-error-codes/#11-administrative-limit-exceeded", 
            "text": "This indicates that an administrative limit was exceeded while processing the request. For example, some directory servers use this response to indicate that it would have required examining too many entries to process the request.", 
            "title": "11: Administrative Limit Exceeded"
        }, 
        {
            "location": "/tools/openldap/ldap-server-error-codes/#12-unavailable-critical-extension", 
            "text": "This indicates that the request included a critical control that was not recognized or could not be processed.", 
            "title": "12: Unavailable Critical Extension"
        }, 
        {
            "location": "/tools/openldap/ldap-server-error-codes/#13-confidentiality-required", 
            "text": "This indicates that the requested operation is only allowed over a secure connection.", 
            "title": "13: Confidentiality Required"
        }, 
        {
            "location": "/tools/openldap/ldap-server-error-codes/#14-sasl-bind-in-progress", 
            "text": "This indicates that the server requires more information from the client in order to complete the SASL bind operation. In such responses, the \"server SASL credentials\" element of the result message will often include information the client needs for subsequent phases of bind processing.", 
            "title": "14: SASL Bind in Progress"
        }, 
        {
            "location": "/tools/openldap/ldap-server-error-codes/#16-no-such-attribute", 
            "text": "This indicates that the client attempted to interact with an attribute that does not exist in the target entry (e.g., to remove an attribute or value that does not exist).", 
            "title": "16: No Such Attribute"
        }, 
        {
            "location": "/tools/openldap/ldap-server-error-codes/#17-undefined-attribute-type", 
            "text": "This indicates that the client request included an attribute type that is not defined in the server schema.", 
            "title": "17: Undefined Attribute Type"
        }, 
        {
            "location": "/tools/openldap/ldap-server-error-codes/#18-inappropriate-matching", 
            "text": "This indicates that the client request attempted to perform an unsupported type of matching against an attribute. For example, this may be used if the attribute type does not have an appropriate matching rule for the type of matching requested for that attribute.", 
            "title": "18: Inappropriate Matching"
        }, 
        {
            "location": "/tools/openldap/ldap-server-error-codes/#19-constraint-violation", 
            "text": "This indicates that the client request would have caused the server to violate some constraint defined in the server (e.g., to add more than one value to a single-valued attribute).", 
            "title": "19: Constraint Violation"
        }, 
        {
            "location": "/tools/openldap/ldap-server-error-codes/#20-attribute-or-value-exists", 
            "text": "This indicates that the client request attempted to add an attribute or value to an entry that already contained that attribute or value.", 
            "title": "20: Attribute or Value Exists"
        }, 
        {
            "location": "/tools/openldap/ldap-server-error-codes/#21-invalid-attribute-syntax", 
            "text": "This indicates that the client request would have resulted in an attribute value that did not conform to the syntax for that attribute type.", 
            "title": "21: Invalid Attribute Syntax"
        }, 
        {
            "location": "/tools/openldap/ldap-server-error-codes/#32-no-such-object", 
            "text": "This indicates that the client request targeted an entry that does not exist. Note that some servers use this result for a bind request that targets a nonexistent user, even though \"invalid credentials\" is a more appropriate result for that case.", 
            "title": "32: No Such Object"
        }, 
        {
            "location": "/tools/openldap/ldap-server-error-codes/#33-alias-problem", 
            "text": "This indicates that a problem was encountered while interacting with an alias entry (e.g., the alias refers to an entry that does not exist).", 
            "title": "33: Alias Problem"
        }, 
        {
            "location": "/tools/openldap/ldap-server-error-codes/#34-invalid-dn-syntax", 
            "text": "This indicates that the request included a malformed or invalid DN or RDN.", 
            "title": "34: Invalid DN Syntax"
        }, 
        {
            "location": "/tools/openldap/ldap-server-error-codes/#36-alias-dereferencing-problem", 
            "text": "This indicates that the client attempted to interact with an alias entry in a manner that was not allowed (e.g., for an operation that does not allow the use of aliases, or if the client does not have permission to access the entry referenced by the alias).", 
            "title": "36: Alias Dereferencing Problem"
        }, 
        {
            "location": "/tools/openldap/ldap-server-error-codes/#48-inappropriate-authentication", 
            "text": "This indicates that the client attempted to perform a type of authentication that is not allowed for the target user (e.g., because the user does not have the necessary credentials for that type of authentication). This may also indicate that the client attempted to perform anonymous authentication when that is not allowed.", 
            "title": "48: Inappropriate Authentication"
        }, 
        {
            "location": "/tools/openldap/ldap-server-error-codes/#49-invalid-credentials", 
            "text": "This indicates that the client attempted to bind as a user that does not exist, attempted to bind as a user that is not allowed to bind (e.g., because it has expired, because it has been locked because of too many failed authentication attempts, etc.), or attempted to bind with credentials that were not correct for the target user.", 
            "title": "49: Invalid Credentials"
        }, 
        {
            "location": "/tools/openldap/ldap-server-error-codes/#50-insufficient-access-rights", 
            "text": "This indicates that the client does not have permission to perform the requested operation.", 
            "title": "50: Insufficient Access Rights"
        }, 
        {
            "location": "/tools/openldap/ldap-server-error-codes/#51-busy", 
            "text": "This indicates that the server is currently too busy to process the requested operation.", 
            "title": "51: Busy"
        }, 
        {
            "location": "/tools/openldap/ldap-server-error-codes/#52-unavailable", 
            "text": "This indicates that the server is currently unavailable (e.g., because it is being shut down or is in a maintenance state).", 
            "title": "52: Unavailable"
        }, 
        {
            "location": "/tools/openldap/ldap-server-error-codes/#53-unwilling-to-perform", 
            "text": "This indicates that the server is unwilling to process the requested operation for some reason.", 
            "title": "53: Unwilling to Perform"
        }, 
        {
            "location": "/tools/openldap/ldap-server-error-codes/#54-loop-detected", 
            "text": "This indicates that the server has detected an internal loop while processing the requested operation (e.g., if two alias entries reference each other).", 
            "title": "54: Loop Detected"
        }, 
        {
            "location": "/tools/openldap/ldap-server-error-codes/#60-sort-control-missing", 
            "text": "This indicates that the search request included a virtual list view request control without also including the required server-side sort request control.", 
            "title": "60: Sort Control Missing"
        }, 
        {
            "location": "/tools/openldap/ldap-server-error-codes/#61-offset-range-error", 
            "text": "This indicates that the search request included a virtual list view request control with an invalid offset or content count.", 
            "title": "61: Offset Range Error"
        }, 
        {
            "location": "/tools/openldap/ldap-server-error-codes/#64-naming-violation", 
            "text": "This indicates that the requested add or modify DN operation would have resulted in an entry that violates server naming restrictions (e.g., as might be imposed by a name form defined in the server schema).", 
            "title": "64: Naming Violation"
        }, 
        {
            "location": "/tools/openldap/ldap-server-error-codes/#65-object-class-violation", 
            "text": "This indicates that the requested operation would have resulted in an entry that violates schema restrictions imposed by its object classes (e.g., to include an attribute that is not allowed to be present in the entry, or to omit an attribute that is required to be present in the entry).", 
            "title": "65: Object Class Violation"
        }, 
        {
            "location": "/tools/openldap/ldap-server-error-codes/#66-not-allowed-on-non-leaf-entry", 
            "text": "This indicates that the requested operation cannot be performed against an entry that has one or more subordinate entries. For example, a delete operation is normally not allowed to remove an entry that has one or more subordinates.", 
            "title": "66: Not Allowed on Non-Leaf Entry"
        }, 
        {
            "location": "/tools/openldap/ldap-server-error-codes/#67-not-allowed-on-rdn", 
            "text": "This indicates that the requested operation is not allowed because it would have altered the entry to remove an attribute value used in the entry's RDN.", 
            "title": "67: Not Allowed on RDN"
        }, 
        {
            "location": "/tools/openldap/ldap-server-error-codes/#68-entry-already-exists", 
            "text": "This indicates that the requested add or modify DN operation could not be processed because another entry already exists with the DN that would have resulted from that operation.", 
            "title": "68: Entry Already Exists"
        }, 
        {
            "location": "/tools/openldap/ldap-server-error-codes/#69-object-class-modifications-prohibited", 
            "text": "This indicates that the requested operation would have resulted in a disallowed change to the object classes contained in the entry (e.g., the operation would have changed the entry's structural object class).", 
            "title": "69: Object Class Modifications Prohibited"
        }, 
        {
            "location": "/tools/openldap/ldap-server-error-codes/#71-affects-multiple-dsas", 
            "text": "This indicates that the requested operation could not be processed because it would have required interacting with data in multiple directory server instances in a way that is not supported.", 
            "title": "71: Affects Multiple DSAs"
        }, 
        {
            "location": "/tools/openldap/ldap-server-error-codes/#76-virtual-list-view-error", 
            "text": "This indicates that a search operation failed because of processing associated with a virtual list view request control included in the request (e.g., if a necessary index was not in place to facilitate the virtual list view processing).", 
            "title": "76: Virtual List View Error"
        }, 
        {
            "location": "/tools/openldap/ldap-server-error-codes/#80-other", 
            "text": "This indicates that some problem was encountered during processing that is not covered by any of the other defined result codes (e.g., a server error).", 
            "title": "80: Other"
        }, 
        {
            "location": "/tools/openldap/ldap-server-error-codes/#118-canceled", 
            "text": "This indicates that an operation was canceled through the use of the cancel extended request. If an operation is canceled in this way, then this result code will be used for both the operation that was canceled and for the cancel extended operation itself.", 
            "title": "118: Canceled"
        }, 
        {
            "location": "/tools/openldap/ldap-server-error-codes/#119-no-such-operation", 
            "text": "This indicates that an attempt to cancel an operation via the cancel extended request was not successful because the server did not have any knowledge of the target operation. This often means that the server had already completed processing for the operation by the time it received and attempted to process the cancel request.", 
            "title": "119: No Such Operation"
        }, 
        {
            "location": "/tools/openldap/ldap-server-error-codes/#120-too-late", 
            "text": "This indicates that an attempt to cancel an operation via the cancel extended request was not successful because processing for that operation had already reached a point beyond which it could be canceled.", 
            "title": "120: Too Late"
        }, 
        {
            "location": "/tools/openldap/ldap-server-error-codes/#121-cannot-cancel", 
            "text": "This indicates that an attempt to cancel an operation via the cancel extended request was not successful because the target operation is not an operation that can be canceled. Operations that cannot be canceled include abandon, bind, unbind, and the cancel and StartTLS extended operations.", 
            "title": "121: Cannot Cancel"
        }, 
        {
            "location": "/tools/openldap/ldap-server-error-codes/#122-assertion-failed", 
            "text": "This indicates that the requested operation could not be processed because the request included an LDAP assertion request control, but the assertion filter did not match the target entry.", 
            "title": "122: Assertion Failed"
        }, 
        {
            "location": "/tools/openldap/ldap-server-error-codes/#123-authorization-denied", 
            "text": "This indicates that the requested operation could not be processed because the request included a proxied authorization request control (or some similar control intended to specify an alternate authorization identity for the operation), but the client was not allowed to request the use of that alternate authorization identity.", 
            "title": "123: Authorization Denied"
        }, 
        {
            "location": "/tools/openldap/ldap-server-error-codes/#4096-synchronization-refresh-required", 
            "text": "This indicates that an attempt to use the content synchronization request control in order to perform an incremental update failed for some reason and the client will instead need to request an initial content.", 
            "title": "4096: Synchronization Refresh Required"
        }, 
        {
            "location": "/tools/openldap/ldap-server-error-codes/#16654-no-operation", 
            "text": "This indicates that the associated operation would likely have succeeded, to the extent that the server was able to make the determination, but was not actually processed because the request included the LDAP no operation control. Note that at present, the numeric value for this result code is not an official standard because the specification for the no operation request control has not progressed far enough to be assigned an official numeric value, but the value 16654 is in common use by a number of servers for this purpose.", 
            "title": "16654: No Operation"
        }, 
        {
            "location": "/tools/openldap/faq/", 
            "text": "OpenLDAP FAQ's\n\n\nHow to generate password for slapd.conf file\n\n\n1\n2\n3\n/opt/openldap/sbin/slappasswd\nNew password:\nRe-enter new password:\n\n\n\n\n\n\ncopy the encrypted password and update the slapd.conf file.\n\n/opt/openldap here, is the install path of openLDAP.\n\n\n[ERROR]: BerkeleyDB not available\n\n\nIf you get one of these errors:\n\n\n\n\nerror:BerkeleyDB not available\n\n\nerror: Berkeley DB version mismatch\n\n\nerror : Berkeley DB library and header version mismatch\n\n\n\n\nthen check if the Berleley Db installation is done correctly. Follow the \ninstallation guide\n for more details on BDB installation.\n\n\nNext, export below env varibales before installing OpenLDAP.\n\n\n1\n2\n3\nexport\n \nCPPFLAGS\n=\n-I/usr/local/BerkeleyDB.4.8/include\n\n\nexport\n \nLDFLAGS\n=\n-L/usr/local/BerkeleyDB.4.8/lib\n\n\nexport\n \nLD_LIBRARY_PATH\n=\n/usr/local/BerkeleyDB.4.8/lib/\n\n\n\n\n\n\n\n/usr/local/BerkeleyDB.4.8 here, is the Berkeley DB install path.\n\n\nReference\n\n\nBerkeley DB version mismatch\n\n\n[ERROR]: soelim is required to build OpenLDAP\n\n\nInstall groff package for linux.\n\n\n1\nyum install groff -y\n\n\n\n\n\n\n[WARNING]: no DB_CONFIG file found in directory /data/openldap\n\n\nYou will get this error while configuring openLDAP if you have not configured a DB_CONFIG file in the data directory.\n\n\nDB_CONFIG\n file holds additional configuration for the Berkeley database.", 
            "title": "FAQ"
        }, 
        {
            "location": "/tools/openldap/faq/#openldap-faqs", 
            "text": "", 
            "title": "OpenLDAP FAQ's"
        }, 
        {
            "location": "/tools/openldap/faq/#how-to-generate-password-for-slapdconf-file", 
            "text": "1\n2\n3 /opt/openldap/sbin/slappasswd\nNew password:\nRe-enter new password:   copy the encrypted password and update the slapd.conf file. \n/opt/openldap here, is the install path of openLDAP.", 
            "title": "How to generate password for slapd.conf file"
        }, 
        {
            "location": "/tools/openldap/faq/#error-berkeleydb-not-available", 
            "text": "If you get one of these errors:   error:BerkeleyDB not available  error: Berkeley DB version mismatch  error : Berkeley DB library and header version mismatch   then check if the Berleley Db installation is done correctly. Follow the  installation guide  for more details on BDB installation.  Next, export below env varibales before installing OpenLDAP.  1\n2\n3 export   CPPFLAGS = -I/usr/local/BerkeleyDB.4.8/include  export   LDFLAGS = -L/usr/local/BerkeleyDB.4.8/lib  export   LD_LIBRARY_PATH = /usr/local/BerkeleyDB.4.8/lib/    /usr/local/BerkeleyDB.4.8 here, is the Berkeley DB install path.  Reference  Berkeley DB version mismatch", 
            "title": "[ERROR]: BerkeleyDB not available"
        }, 
        {
            "location": "/tools/openldap/faq/#error-soelim-is-required-to-build-openldap", 
            "text": "Install groff package for linux.  1 yum install groff -y", 
            "title": "[ERROR]: soelim is required to build OpenLDAP"
        }, 
        {
            "location": "/tools/openldap/faq/#warning-no-db_config-file-found-in-directory-dataopenldap", 
            "text": "You will get this error while configuring openLDAP if you have not configured a DB_CONFIG file in the data directory.  DB_CONFIG  file holds additional configuration for the Berkeley database.", 
            "title": "[WARNING]: no DB_CONFIG file found in directory /data/openldap"
        }, 
        {
            "location": "/tools/jenkins/", 
            "text": "", 
            "title": "Introduction"
        }, 
        {
            "location": "/docker/", 
            "text": "Docker\n\n\nOverview\n\n\nDocker is the world\u2019s leading software container platform. Developers use Docker to eliminate \u201cworks on my machine\u201d problems when collaborating on code with co-workers. Operators use Docker to run and manage apps side-by-side in isolated containers to get better compute density. Enterprises use Docker to build agile software delivery pipelines to ship new features faster, more securely and with confidence for both Linux and Windows Server apps.\n\n\n...more information\n\n\nWhat is a Container?\n\n\nUsing containers, everything required to make a piece of software run is packaged into isolated containers. Unlike VMs, containers do not bundle a full operating system - only libraries and settings required to make the software work are needed. This makes for efficient, lightweight, self-contained systems and guarantees that software will always run the same, regardless of where it\u2019s deployed.\n\n\n...more information\n\n\nVirtual Machine v/s Containers\n\n\n\n\n\n\nWhat makes docker different that VMs?\n\n\n\n\nGet Started with Docker\n\n\nPlease follow the \ngetting started guide\n.\n\n\nMandatory Reading\n\n\n\n\nDockerfile reference\n\n\nDockerfile best practices\n\n\nDockerfile linting\n\n\n\n\nFurther Reading\n\n\n\n\nTwelve Factor Container\n\n\nDocker metrics Prometheus\n\n\nDocker Datacenter (Docker EE)\n\n\nDocker Swarm Tutorials\n\n\nViktor Farcic's Presentations and Workshops", 
            "title": "Introduction"
        }, 
        {
            "location": "/docker/#docker", 
            "text": "", 
            "title": "Docker"
        }, 
        {
            "location": "/docker/#overview", 
            "text": "Docker is the world\u2019s leading software container platform. Developers use Docker to eliminate \u201cworks on my machine\u201d problems when collaborating on code with co-workers. Operators use Docker to run and manage apps side-by-side in isolated containers to get better compute density. Enterprises use Docker to build agile software delivery pipelines to ship new features faster, more securely and with confidence for both Linux and Windows Server apps.  ...more information", 
            "title": "Overview"
        }, 
        {
            "location": "/docker/#what-is-a-container", 
            "text": "Using containers, everything required to make a piece of software run is packaged into isolated containers. Unlike VMs, containers do not bundle a full operating system - only libraries and settings required to make the software work are needed. This makes for efficient, lightweight, self-contained systems and guarantees that software will always run the same, regardless of where it\u2019s deployed.  ...more information", 
            "title": "What is a Container?"
        }, 
        {
            "location": "/docker/#virtual-machine-vs-containers", 
            "text": "What makes docker different that VMs?", 
            "title": "Virtual Machine v/s Containers"
        }, 
        {
            "location": "/docker/#get-started-with-docker", 
            "text": "Please follow the  getting started guide .", 
            "title": "Get Started with Docker"
        }, 
        {
            "location": "/docker/#mandatory-reading", 
            "text": "Dockerfile reference  Dockerfile best practices  Dockerfile linting", 
            "title": "Mandatory Reading"
        }, 
        {
            "location": "/docker/#further-reading", 
            "text": "Twelve Factor Container  Docker metrics Prometheus  Docker Datacenter (Docker EE)  Docker Swarm Tutorials  Viktor Farcic's Presentations and Workshops", 
            "title": "Further Reading"
        }, 
        {
            "location": "/docker/docker-compose/", 
            "text": "Docker Compose\n\n\nOverview\n\n\nCompose is a tool for defining and running multi-container Docker applications. With Compose, you use a Compose file to configure your application\u2019s services. Then, using a single command, you create and start all the services from your configuration.\n\n\nUsing Compose is basically a three-step process:\n\n\n\n\nDefine your app\u2019s environment with a Dockerfile so it can be reproduced anywhere.\n\n\nDefine the services that make up your app in docker-compose.yml so they can be run together in an isolated environment.\n\n\nLastly, run docker-compose up and Compose will start and run your entire app.\n\n\n\n\nA docker-compose.yml looks like \nthis", 
            "title": "Docker Compose"
        }, 
        {
            "location": "/docker/docker-compose/#docker-compose", 
            "text": "", 
            "title": "Docker Compose"
        }, 
        {
            "location": "/docker/docker-compose/#overview", 
            "text": "Compose is a tool for defining and running multi-container Docker applications. With Compose, you use a Compose file to configure your application\u2019s services. Then, using a single command, you create and start all the services from your configuration.  Using Compose is basically a three-step process:   Define your app\u2019s environment with a Dockerfile so it can be reproduced anywhere.  Define the services that make up your app in docker-compose.yml so they can be run together in an isolated environment.  Lastly, run docker-compose up and Compose will start and run your entire app.   A docker-compose.yml looks like  this", 
            "title": "Overview"
        }, 
        {
            "location": "/docker/docker-machine/", 
            "text": "Docker Machine\n\n\nDocker Machine is a tool that lets you install Docker Engine on virtual hosts, and manage the hosts with docker-machine commands. You can use Machine to create Docker hosts on your local Mac or Windows box, on your company network, in your data center, or on cloud providers like AWS or Digital Ocean.\nUsing docker-machine commands, you can start, inspect, stop, and restart a managed host, upgrade the Docker client and daemon, and configure a Docker client to talk to your host.", 
            "title": "Docker Machine"
        }, 
        {
            "location": "/docker/docker-machine/#docker-machine", 
            "text": "Docker Machine is a tool that lets you install Docker Engine on virtual hosts, and manage the hosts with docker-machine commands. You can use Machine to create Docker hosts on your local Mac or Windows box, on your company network, in your data center, or on cloud providers like AWS or Digital Ocean.\nUsing docker-machine commands, you can start, inspect, stop, and restart a managed host, upgrade the Docker client and daemon, and configure a Docker client to talk to your host.", 
            "title": "Docker Machine"
        }, 
        {
            "location": "/docker/docker-networks/", 
            "text": "Docker Networks\n\n\nThis section provides an overview of Docker\u2019s default networking behavior, including the type of networks created by default and how to create your own user-defined networks. It also describes the resources required to create networks on a single host or across a cluster of hosts.\n\n\nDefault Networks\n\n\nWhen you install Docker, it creates three networks automatically. You can list these networks using the docker network ls command:\n\n\n1\n2\n3\n4\n5\n6\n$ docker network ls\n\nNETWORK ID          NAME                DRIVER\n7fca4eb8c647        bridge              bridge\n9f904ee27bf5        none                null\ncf03ee007fb4        host                host\n\n\n\n\n\n\n...more information\n\n\nUser-defined networks\n\n\nIt is recommended to use user-defined bridge networks to control which containers can communicate with each other, and also to enable automatic DNS resolution of container names to IP addresses.\n\n\n...more information\n\n\nBridge networks\n\n\nA bridge network is the most common type of network used in Docker. Bridge networks are similar to the default bridge network, but add some new features and remove some old abilities. The following examples create some bridge networks and perform some experiments on containers on these networks.\n\n\n1\n2\ndocker network create --driver bridge isolated_nw\ndocker network inspect isolated_nw\n\n\n\n\n\n\nAfter you create the network, you can launch containers on it using the docker run \n--network=\nNETWORK\n option.", 
            "title": "Docker Networks"
        }, 
        {
            "location": "/docker/docker-networks/#docker-networks", 
            "text": "This section provides an overview of Docker\u2019s default networking behavior, including the type of networks created by default and how to create your own user-defined networks. It also describes the resources required to create networks on a single host or across a cluster of hosts.", 
            "title": "Docker Networks"
        }, 
        {
            "location": "/docker/docker-networks/#default-networks", 
            "text": "When you install Docker, it creates three networks automatically. You can list these networks using the docker network ls command:  1\n2\n3\n4\n5\n6 $ docker network ls\n\nNETWORK ID          NAME                DRIVER\n7fca4eb8c647        bridge              bridge\n9f904ee27bf5        none                null\ncf03ee007fb4        host                host   ...more information", 
            "title": "Default Networks"
        }, 
        {
            "location": "/docker/docker-networks/#user-defined-networks", 
            "text": "It is recommended to use user-defined bridge networks to control which containers can communicate with each other, and also to enable automatic DNS resolution of container names to IP addresses.  ...more information", 
            "title": "User-defined networks"
        }, 
        {
            "location": "/docker/docker-networks/#bridge-networks", 
            "text": "A bridge network is the most common type of network used in Docker. Bridge networks are similar to the default bridge network, but add some new features and remove some old abilities. The following examples create some bridge networks and perform some experiments on containers on these networks.  1\n2 docker network create --driver bridge isolated_nw\ndocker network inspect isolated_nw   After you create the network, you can launch containers on it using the docker run  --network= NETWORK  option.", 
            "title": "Bridge networks"
        }, 
        {
            "location": "/docker/docker-secrets/", 
            "text": "Docker Secrets\n\nhttps://docs.docker.com/engine/swarm/secrets/#how-docker-manages-secrets", 
            "title": "Docker Secrets"
        }, 
        {
            "location": "/golang/", 
            "text": "Go Programing Language [golang]\n\n\n\n\nGo is an open source programming language that makes it easy to build simple, reliable, and efficient software.\n\n\n\n\n\n\nWhy Go?\n\n\n9 reasons to choose GoLang for your next web application\n\n\nInstallation\n\n\nSetting up your workspace\n\n\n\n\nImportant links\n\n\n\n\nGetting started with Go\n\n\nJSON Validator\n\n\nJSON to Go Struct\n\n\nCurl to Go\n\n\nPointers Vs Values\n\n\nGo for Java programers\n\n\nFetch JSON from an API\n\n\nGo Slices (arrays / lists)\n\n\nForEach loop\n\n\nGo Report card\n\n\nBest Practices\n\n\nInterfaces in go", 
            "title": "Introduction"
        }, 
        {
            "location": "/golang/#go-programing-language-golang", 
            "text": "Go is an open source programming language that makes it easy to build simple, reliable, and efficient software.    Why Go?  9 reasons to choose GoLang for your next web application  Installation  Setting up your workspace", 
            "title": "Go Programing Language [golang]"
        }, 
        {
            "location": "/golang/#important-links", 
            "text": "Getting started with Go  JSON Validator  JSON to Go Struct  Curl to Go  Pointers Vs Values  Go for Java programers  Fetch JSON from an API  Go Slices (arrays / lists)  ForEach loop  Go Report card  Best Practices  Interfaces in go", 
            "title": "Important links"
        }, 
        {
            "location": "/golang/http-request/", 
            "text": "Http request in Go\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n74\n75\n76\n77\n78\n79\n80\n81\n82\n83\n84\npackage\n \nmain\n\n\n\nimport\n \n(\n\n    \nnet/http\n\n    \nbytes\n\n    \nfmt\n\n    \nio/ioutil\n\n    \nlog\n\n    \nnet/url\n\n\n)\n\n\n\nfunc\n \nmain\n()\n \n{\n\n    \n//Call the http function to create and make a http request\n\n\n}\n\n\n\n// AuthUser represents the credential for Authentication\n\n\ntype\n \nAuthUser\n \nstruct\n \n{\n\n    \nUsername\n \nstring\n\n    \nPassword\n \nstring\n\n\n}\n\n\n\n/*\n\n\nError prints error\n\n\n@param err error  error details\n\n\n@return void\n\n\n*/\n\n\nfunc\n \nError\n(\nerr\n \nerror\n,\n \nerrorMessage\n \nstring\n)\n \n{\n\n    \nif\n \nerr\n \n!=\n \nnil\n \n{\n\n        \nlog\n.\nPrintln\n(\nerrorMessage\n)\n\n        \nlog\n.\nFatal\n(\nerr\n)\n\n    \n}\n\n\n}\n\n\n\n/*\n\n\nCreateBaseRequest create the base request for a HTTP request\n\n\n@param method   string          http request method eg: GET, POST, etc\n\n\n@param url      string          http request url\n\n\n@param body     []byte          request body\n\n\n@param user     m.AuthUser      User authentication details\n\n\n@param verbose  boolean         prints verbose logs if set to true\n\n\n@return *http.Request   HTTP base request\n\n\n*/\n\n\nfunc\n \nCreateBaseRequest\n(\nmethod\n,\n \nurl\n \nstring\n,\n \nbody\n \n[]\nbyte\n,\n \nuser\n \nAuthUser\n,\n \nverbose\n \nbool\n)\n \n*\nhttp\n.\nRequest\n \n{\n\n    \nreq\n,\n \nerr\n \n:=\n \nhttp\n.\nNewRequest\n(\nmethod\n,\n \nurl\n,\n \nbytes\n.\nNewBuffer\n(\nbody\n))\n\n    \nreq\n.\nSetBasicAuth\n(\nuser\n.\nUsername\n,\n \nuser\n.\nPassword\n)\n\n    \nreq\n.\nHeader\n.\nSet\n(\nContent-Type\n,\n \napplication/json\n)\n\n    \nreq\n.\nHeader\n.\nSet\n(\nAccept\n,\n \napplication/json\n)\n\n    \nError\n(\nerr\n,\n \nError creating the request\n)\n\n\n    \nif\n \nverbose\n \n{\n\n        \nfmt\n.\nPrintln\n(\nRequest Url:\n,\n \nreq\n.\nURL\n)\n\n        \nfmt\n.\nPrintln\n(\nRequest Headers:\n,\n \nreq\n.\nHeader\n)\n\n        \nfmt\n.\nPrintln\n(\nRequest Body:\n,\n \nreq\n.\nBody\n)\n\n    \n}\n\n\n    \nreturn\n \nreq\n\n\n}\n\n\n\n/*\n\n\nHTTPRequest makes a request to the remote server via a proxy server\n\n\n@param user     m.AuthUser      User authentication details\n\n\n@param req      *http.Request   HTTP base request\n\n\n@param verbose  boolean         prints verbose logs if set to true\n\n\n@return []byte  response body\n\n\n@return string  response status\n\n\n*/\n\n\nfunc\n \nHTTPRequest\n(\nuser\n \nAuthUser\n,\n \nreq\n \n*\nhttp\n.\nRequest\n,\n \nverbose\n \nbool\n)\n \n([]\nbyte\n,\n \nstring\n)\n \n{\n\n\n    \nclient\n \n:=\n \nhttp\n.\nClient\n{}\n\n\n    \nresp\n,\n \nerr\n \n:=\n \nclient\n.\nDo\n(\nreq\n)\n\n    \nError\n(\nerr\n,\n \nThere was a problem in making the request\n)\n\n\n    \ndefer\n \nresp\n.\nBody\n.\nClose\n()\n\n    \nrespBody\n,\n \nerr\n \n:=\n \nioutil\n.\nReadAll\n(\nresp\n.\nBody\n)\n\n    \nError\n(\nerr\n,\n \nThere was a problem reading the response body\n)\n\n\n    \nif\n \nverbose\n \n{\n\n        \nfmt\n.\nPrintln\n(\nResponse Headers:\n,\n \nresp\n.\nHeader\n)\n\n        \nfmt\n.\nPrintln\n(\nResponse Status:\n,\n \nresp\n.\nStatus\n)\n\n        \nfmt\n.\nPrintln\n(\nResponse Body:\n,\n \nstring\n(\nrespBody\n))\n\n    \n}\n\n    \nreturn\n \nrespBody\n,\n \nresp\n.\nStatus\n\n\n}", 
            "title": "Http Request in Go"
        }, 
        {
            "location": "/golang/http-request/#http-request-in-go", 
            "text": "1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n74\n75\n76\n77\n78\n79\n80\n81\n82\n83\n84 package   main  import   ( \n     net/http \n     bytes \n     fmt \n     io/ioutil \n     log \n     net/url  )  func   main ()   { \n     //Call the http function to create and make a http request  }  // AuthUser represents the credential for Authentication  type   AuthUser   struct   { \n     Username   string \n     Password   string  }  /*  Error prints error  @param err error  error details  @return void  */  func   Error ( err   error ,   errorMessage   string )   { \n     if   err   !=   nil   { \n         log . Println ( errorMessage ) \n         log . Fatal ( err ) \n     }  }  /*  CreateBaseRequest create the base request for a HTTP request  @param method   string          http request method eg: GET, POST, etc  @param url      string          http request url  @param body     []byte          request body  @param user     m.AuthUser      User authentication details  @param verbose  boolean         prints verbose logs if set to true  @return *http.Request   HTTP base request  */  func   CreateBaseRequest ( method ,   url   string ,   body   [] byte ,   user   AuthUser ,   verbose   bool )   * http . Request   { \n     req ,   err   :=   http . NewRequest ( method ,   url ,   bytes . NewBuffer ( body )) \n     req . SetBasicAuth ( user . Username ,   user . Password ) \n     req . Header . Set ( Content-Type ,   application/json ) \n     req . Header . Set ( Accept ,   application/json ) \n     Error ( err ,   Error creating the request ) \n\n     if   verbose   { \n         fmt . Println ( Request Url: ,   req . URL ) \n         fmt . Println ( Request Headers: ,   req . Header ) \n         fmt . Println ( Request Body: ,   req . Body ) \n     } \n\n     return   req  }  /*  HTTPRequest makes a request to the remote server via a proxy server  @param user     m.AuthUser      User authentication details  @param req      *http.Request   HTTP base request  @param verbose  boolean         prints verbose logs if set to true  @return []byte  response body  @return string  response status  */  func   HTTPRequest ( user   AuthUser ,   req   * http . Request ,   verbose   bool )   ([] byte ,   string )   { \n\n     client   :=   http . Client {} \n\n     resp ,   err   :=   client . Do ( req ) \n     Error ( err ,   There was a problem in making the request ) \n\n     defer   resp . Body . Close () \n     respBody ,   err   :=   ioutil . ReadAll ( resp . Body ) \n     Error ( err ,   There was a problem reading the response body ) \n\n     if   verbose   { \n         fmt . Println ( Response Headers: ,   resp . Header ) \n         fmt . Println ( Response Status: ,   resp . Status ) \n         fmt . Println ( Response Body: ,   string ( respBody )) \n     } \n     return   respBody ,   resp . Status  }", 
            "title": "Http request in Go"
        }, 
        {
            "location": "/golang/http-request-proxy/", 
            "text": "HTTP Request Via A Proxy\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n74\n75\n76\n77\n78\n79\n80\n81\n82\n83\n84\n85\n86\n87\n88\n89\n90\n91\n92\n93\n94\npackage\n \nmain\n\n\n\nimport\n \n(\n\n    \nnet/http\n\n    \nbytes\n\n    \nfmt\n\n    \nio/ioutil\n\n    \nlog\n\n    \nnet/url\n\n\n)\n\n\n\nfunc\n \nmain\n()\n \n{\n\n    \n//Call the http function to create and make a http request\n\n\n}\n\n\n\n// AuthUser represents the credential for Authentication\n\n\ntype\n \nAuthUser\n \nstruct\n \n{\n\n    \nUsername\n \nstring\n\n    \nPassword\n \nstring\n\n\n}\n\n\n\n/*\n\n\nError prints error\n\n\n@param err error  error details\n\n\n@return void\n\n\n*/\n\n\nfunc\n \nError\n(\nerr\n \nerror\n,\n \nerrorMessage\n \nstring\n)\n \n{\n\n    \nif\n \nerr\n \n!=\n \nnil\n \n{\n\n        \nlog\n.\nPrintln\n(\nerrorMessage\n)\n\n        \nlog\n.\nFatal\n(\nerr\n)\n\n    \n}\n\n\n}\n\n\n\n/*\n\n\nCreateBaseRequest create the base request for a HTTP request\n\n\n@param method   string          http request method eg: GET, POST, etc\n\n\n@param url      string          http request url\n\n\n@param body     []byte          request body\n\n\n@param user     m.AuthUser      User authentication details\n\n\n@param verbose  boolean         prints verbose logs if set to true\n\n\n@return *http.Request   HTTP base request\n\n\n*/\n\n\nfunc\n \nCreateBaseRequest\n(\nmethod\n,\n \nurl\n \nstring\n,\n \nbody\n \n[]\nbyte\n,\n \nuser\n \nAuthUser\n,\n \nverbose\n \nbool\n)\n \n*\nhttp\n.\nRequest\n \n{\n\n    \nreq\n,\n \nerr\n \n:=\n \nhttp\n.\nNewRequest\n(\nmethod\n,\n \nurl\n,\n \nbytes\n.\nNewBuffer\n(\nbody\n))\n\n    \nreq\n.\nSetBasicAuth\n(\nuser\n.\nUsername\n,\n \nuser\n.\nPassword\n)\n\n    \nreq\n.\nHeader\n.\nSet\n(\nContent-Type\n,\n \napplication/json\n)\n\n    \nreq\n.\nHeader\n.\nSet\n(\nAccept\n,\n \napplication/json\n)\n\n    \nError\n(\nerr\n,\n \nError creating the request\n)\n\n\n    \nif\n \nverbose\n \n{\n\n        \nfmt\n.\nPrintln\n(\nRequest Url:\n,\n \nreq\n.\nURL\n)\n\n        \nfmt\n.\nPrintln\n(\nRequest Headers:\n,\n \nreq\n.\nHeader\n)\n\n        \nfmt\n.\nPrintln\n(\nRequest Body:\n,\n \nreq\n.\nBody\n)\n\n    \n}\n\n\n    \nreturn\n \nreq\n\n\n}\n\n\n\n/*\n\n\nHTTPRequest makes a request to the remote server via a proxy server\n\n\n@param user     m.AuthUser      User authentication details\n\n\n@param req      *http.Request   HTTP base request\n\n\n@param verbose  boolean         prints verbose logs if set to true\n\n\n@return []byte  response body\n\n\n@return string  response status\n\n\n*/\n\n\nfunc\n \nHTTPRequest\n(\nuser\n \nAuthUser\n,\n \nreq\n \n*\nhttp\n.\nRequest\n,\n \nverbose\n \nbool\n)\n \n([]\nbyte\n,\n \nstring\n)\n \n{\n\n\n    \nclient\n \n:=\n \nhttp\n.\nClient\n{}\n\n\n    \n// Proxy Settings\n\n    \nproxyURL\n \n:=\n \nhttp://proxy-host:proxy-port\n\n    \nproxyUrl\n,\n \n_\n \n:=\n \nurl\n.\nParse\n(\nproxyURL\n)\n\n\n    \ntransport\n \n:=\n \nhttp\n.\nTransport\n{\n\n        \nProxy\n:\n \nhttp\n.\nProxyURL\n(\nproxyUrl\n),\n\n    \n}\n\n\n    \nclient\n.\nTransport\n \n=\n \ntransport\n\n\n    \nresp\n,\n \nerr\n \n:=\n \nclient\n.\nDo\n(\nreq\n)\n\n    \nError\n(\nerr\n,\n \nThere was a problem in making the request\n)\n\n\n    \ndefer\n \nresp\n.\nBody\n.\nClose\n()\n\n    \nrespBody\n,\n \nerr\n \n:=\n \nioutil\n.\nReadAll\n(\nresp\n.\nBody\n)\n\n    \nError\n(\nerr\n,\n \nThere was a problem reading the response body\n)\n\n\n    \nif\n \nverbose\n \n{\n\n        \nfmt\n.\nPrintln\n(\nResponse Headers:\n,\n \nresp\n.\nHeader\n)\n\n        \nfmt\n.\nPrintln\n(\nResponse Status:\n,\n \nresp\n.\nStatus\n)\n\n        \nfmt\n.\nPrintln\n(\nResponse Body:\n,\n \nstring\n(\nrespBody\n))\n\n    \n}\n\n    \nreturn\n \nrespBody\n,\n \nresp\n.\nStatus\n\n\n}", 
            "title": "Http Request via a Proxy"
        }, 
        {
            "location": "/golang/http-request-proxy/#http-request-via-a-proxy", 
            "text": "1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n74\n75\n76\n77\n78\n79\n80\n81\n82\n83\n84\n85\n86\n87\n88\n89\n90\n91\n92\n93\n94 package   main  import   ( \n     net/http \n     bytes \n     fmt \n     io/ioutil \n     log \n     net/url  )  func   main ()   { \n     //Call the http function to create and make a http request  }  // AuthUser represents the credential for Authentication  type   AuthUser   struct   { \n     Username   string \n     Password   string  }  /*  Error prints error  @param err error  error details  @return void  */  func   Error ( err   error ,   errorMessage   string )   { \n     if   err   !=   nil   { \n         log . Println ( errorMessage ) \n         log . Fatal ( err ) \n     }  }  /*  CreateBaseRequest create the base request for a HTTP request  @param method   string          http request method eg: GET, POST, etc  @param url      string          http request url  @param body     []byte          request body  @param user     m.AuthUser      User authentication details  @param verbose  boolean         prints verbose logs if set to true  @return *http.Request   HTTP base request  */  func   CreateBaseRequest ( method ,   url   string ,   body   [] byte ,   user   AuthUser ,   verbose   bool )   * http . Request   { \n     req ,   err   :=   http . NewRequest ( method ,   url ,   bytes . NewBuffer ( body )) \n     req . SetBasicAuth ( user . Username ,   user . Password ) \n     req . Header . Set ( Content-Type ,   application/json ) \n     req . Header . Set ( Accept ,   application/json ) \n     Error ( err ,   Error creating the request ) \n\n     if   verbose   { \n         fmt . Println ( Request Url: ,   req . URL ) \n         fmt . Println ( Request Headers: ,   req . Header ) \n         fmt . Println ( Request Body: ,   req . Body ) \n     } \n\n     return   req  }  /*  HTTPRequest makes a request to the remote server via a proxy server  @param user     m.AuthUser      User authentication details  @param req      *http.Request   HTTP base request  @param verbose  boolean         prints verbose logs if set to true  @return []byte  response body  @return string  response status  */  func   HTTPRequest ( user   AuthUser ,   req   * http . Request ,   verbose   bool )   ([] byte ,   string )   { \n\n     client   :=   http . Client {} \n\n     // Proxy Settings \n     proxyURL   :=   http://proxy-host:proxy-port \n     proxyUrl ,   _   :=   url . Parse ( proxyURL ) \n\n     transport   :=   http . Transport { \n         Proxy :   http . ProxyURL ( proxyUrl ), \n     } \n\n     client . Transport   =   transport \n\n     resp ,   err   :=   client . Do ( req ) \n     Error ( err ,   There was a problem in making the request ) \n\n     defer   resp . Body . Close () \n     respBody ,   err   :=   ioutil . ReadAll ( resp . Body ) \n     Error ( err ,   There was a problem reading the response body ) \n\n     if   verbose   { \n         fmt . Println ( Response Headers: ,   resp . Header ) \n         fmt . Println ( Response Status: ,   resp . Status ) \n         fmt . Println ( Response Body: ,   string ( respBody )) \n     } \n     return   respBody ,   resp . Status  }", 
            "title": "HTTP Request Via A Proxy"
        }, 
        {
            "location": "/golang/string-functions/", 
            "text": "String Functions in Go\n\n\nTitle\n\n\nCapitalize a string\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\npackage\n \nmain\n\n\n\nimport\n \n(\n\n    \nfmt\n\n    \nstrings\n\n\n)\n\n\n\nfunc\n \nmain\n()\n \n{\n\n    \nstring\n \n:=\n \nmy name is allan\n\n    \nfmt\n.\nPrintln\n(\nTitle : \n,\n \nstrings\n.\nTitle\n(\nstring\n))\n\n\n}\n\n\n// Output:\n\n\n//Title :  My Name Is Allan\n\n\n\n\n\n\n\nToLower\n\n\nConvert a string to lower case\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\npackage\n \nmain\n\n\n\nimport\n \n(\n\n    \nfmt\n\n    \nstrings\n\n\n)\n\n\n\nfunc\n \nmain\n()\n \n{\n\n    \nstring\n \n:=\n \nMY Name IS AllAn\n\n    \nfmt\n.\nPrintln\n(\nToLower : \n,\n \nstrings\n.\nToLower\n(\nstring\n))\n\n\n}\n\n\n//Output:\n\n\n//ToLower :  my name is allan\n\n\n\n\n\n\n\nToUpper\n\n\nConver a string to upper case\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\npackage\n \nmain\n\n\n\nimport\n \n(\n\n    \nfmt\n\n    \nstrings\n\n\n)\n\n\n\nfunc\n \nmain\n()\n \n{\n\n    \nstring\n \n:=\n \nMY Name IS AllAn\n\n\nfmt\n.\nPrintln\n(\nToUpper : \n,\n \nstrings\n.\nToUpper\n(\nstring\n))\n\n\n}\n\n\n//Output:\n\n\n//ToUpper :  MY NAME IS ALLAN\n\n\n\n\n\n\n\nContains\n\n\nChecks if a string contains a substring\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\npackage\n \nmain\n\n\n\nimport\n \n(\n\n    \nfmt\n\n    \nstrings\n\n\n)\n\n\n\nfunc\n \nmain\n()\n \n{\n\n    \nstring\n \n:=\n \nMy name is Allan\n\n    \nfmt\n.\nPrintln\n(\nContains : \n,\n \nstrings\n.\nContains\n(\nstring\n,\n \nAllan\n))\n\n    \nfmt\n.\nPrintln\n(\nContains : \n,\n \nstrings\n.\nContains\n(\nstring\n,\n \nsomething\n))\n\n\n}\n\n\n//Output:\n\n\n//Contains :  true\n\n\n//Contains :  false\n\n\n\n\n\n\n\nReplace\n\n\nReplace a substring with another\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\npackage\n \nmain\n\n\n\nimport\n \n(\n\n    \nfmt\n\n    \nstrings\n\n\n)\n\n\n\nfunc\n \nmain\n()\n \n{\n\n    \nstring\n \n:=\n \nMy name is Allan\n\n    \nfmt\n.\nPrintln\n(\nReplace : \n,\n \nstrings\n.\nReplace\n(\nstring\n,\n \nAllan\n,\n \nAllan Selvan\n,\n \n1\n))\n\n\n}\n\n\n//Output:\n\n\n//Replace :  My name is Allan Selvan\n\n\n\n\n\n\n\nSplit\n\n\nSplit a string\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\npackage\n \nmain\n\n\n\nimport\n \n(\n\n    \nfmt\n\n    \nstrings\n\n\n)\n\n\n\nfunc\n \nmain\n()\n \n{\n\n    \nstring\n \n:=\n \nstone,paper,scissor\n\n    \nfmt\n.\nPrintln\n(\nSplit : \n,\n \nstrings\n.\nSplit\n(\nstring\n,\n \n,\n))\n\n\n}\n\n\n//Output:\n\n\n//Split :  [stone paper scissor]\n\n\n\n\n\n\n\nJoin\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\npackage\n \nmain\n\n\n\nimport\n \n(\n\n    \nfmt\n\n    \nstrings\n\n\n)\n\n\n\nfunc\n \nmain\n()\n \n{\n\n    \nstring\n \n:=\n \n[]\nstring\n{\nstone\n,\n \npaper\n,\n \nscissor\n}\n\n    \nfmt\n.\nPrintln\n(\nJoin : \n,\n \nstrings\n.\nJoin\n(\nstring\n,\n \n,\n))\n\n\n}\n\n\n//Output:\n\n\n//Join :  stone,paper,scissor", 
            "title": "String Functions"
        }, 
        {
            "location": "/golang/string-functions/#string-functions-in-go", 
            "text": "", 
            "title": "String Functions in Go"
        }, 
        {
            "location": "/golang/string-functions/#title", 
            "text": "Capitalize a string   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13 package   main  import   ( \n     fmt \n     strings  )  func   main ()   { \n     string   :=   my name is allan \n     fmt . Println ( Title :  ,   strings . Title ( string ))  }  // Output:  //Title :  My Name Is Allan", 
            "title": "Title"
        }, 
        {
            "location": "/golang/string-functions/#tolower", 
            "text": "Convert a string to lower case   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13 package   main  import   ( \n     fmt \n     strings  )  func   main ()   { \n     string   :=   MY Name IS AllAn \n     fmt . Println ( ToLower :  ,   strings . ToLower ( string ))  }  //Output:  //ToLower :  my name is allan", 
            "title": "ToLower"
        }, 
        {
            "location": "/golang/string-functions/#toupper", 
            "text": "Conver a string to upper case   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13 package   main  import   ( \n     fmt \n     strings  )  func   main ()   { \n     string   :=   MY Name IS AllAn  fmt . Println ( ToUpper :  ,   strings . ToUpper ( string ))  }  //Output:  //ToUpper :  MY NAME IS ALLAN", 
            "title": "ToUpper"
        }, 
        {
            "location": "/golang/string-functions/#contains", 
            "text": "Checks if a string contains a substring   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15 package   main  import   ( \n     fmt \n     strings  )  func   main ()   { \n     string   :=   My name is Allan \n     fmt . Println ( Contains :  ,   strings . Contains ( string ,   Allan )) \n     fmt . Println ( Contains :  ,   strings . Contains ( string ,   something ))  }  //Output:  //Contains :  true  //Contains :  false", 
            "title": "Contains"
        }, 
        {
            "location": "/golang/string-functions/#replace", 
            "text": "Replace a substring with another   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13 package   main  import   ( \n     fmt \n     strings  )  func   main ()   { \n     string   :=   My name is Allan \n     fmt . Println ( Replace :  ,   strings . Replace ( string ,   Allan ,   Allan Selvan ,   1 ))  }  //Output:  //Replace :  My name is Allan Selvan", 
            "title": "Replace"
        }, 
        {
            "location": "/golang/string-functions/#split", 
            "text": "Split a string   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13 package   main  import   ( \n     fmt \n     strings  )  func   main ()   { \n     string   :=   stone,paper,scissor \n     fmt . Println ( Split :  ,   strings . Split ( string ,   , ))  }  //Output:  //Split :  [stone paper scissor]", 
            "title": "Split"
        }, 
        {
            "location": "/golang/string-functions/#join", 
            "text": "1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13 package   main  import   ( \n     fmt \n     strings  )  func   main ()   { \n     string   :=   [] string { stone ,   paper ,   scissor } \n     fmt . Println ( Join :  ,   strings . Join ( string ,   , ))  }  //Output:  //Join :  stone,paper,scissor", 
            "title": "Join"
        }, 
        {
            "location": "/golang/slices/", 
            "text": "Slices in Go\n\n\nDeclaring a slice\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\npackage\n \nmain\n\n\n\nimport\n \nfmt\n\n\n\nfunc\n \nmain\n()\n \n{\n\n    \nletters\n \n:=\n \n[]\nstring\n{\na\n,\n \nb\n,\n \nc\n,\n \nd\n}\n\n    \nfmt\n.\nPrintln\n(\nletters\n)\n\n\n}\n\n\n//Output: \n\n\n//[a b c d]\n\n\n\n\n\n\n\nAdding a entry to a slice\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\npackage\n \nmain\n\n\n\nimport\n \nfmt\n\n\n\nfunc\n \nmain\n()\n \n{\n\n    \nletters\n \n:=\n \n[]\nstring\n{\na\n,\n \nb\n,\n \nc\n,\n \nd\n}\n\n    \nletters\n \n=\n \nappend\n(\nletters\n,\n \ne\n)\n\n    \nfmt\n.\nPrintln\n(\nletters\n)\n\n\n}\n\n\n//Output: \n\n\n//[a b c d e]\n\n\n\n\n\n\n\nGet the length of a slice\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\npackage\n \nmain\n\n\n\nimport\n \nfmt\n\n\n\nfunc\n \nmain\n()\n \n{\n\n    \nletters\n \n:=\n \n[]\nstring\n{\na\n,\n \nb\n,\n \nc\n,\n \nd\n}\n\n    \nfmt\n.\nPrintln\n(\nletters\n)\n\n    \nfmt\n.\nPrintln\n(\nLength of the slice is : \n,\n \nlen\n(\nletters\n))\n\n\n}\n\n\n//Output:\n\n\n//[a b c d]\n\n\n//Length of the slice is :  4\n\n\n\n\n\n\n\nCheck if a entry exists in a slice\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\npackage\n \nmain\n\n\n\nimport\n \nfmt\n\n\n\nfunc\n \nmain\n()\n \n{\n\n    \nletters\n \n:=\n \n[]\nstring\n{\na\n,\n \nb\n,\n \nc\n,\n \nd\n}\n\n    \nfmt\n.\nPrintln\n(\nentryExists\n(\nletters\n,\n \na\n))\n\n    \nfmt\n.\nPrintln\n(\nentryExists\n(\nletters\n,\n \ne\n))\n\n\n}\n\n\n\nfunc\n \nentryExists\n(\nslice\n \n[]\nstring\n,\n \nentry\n \nstring\n)\n \nbool\n{\n\n    \nfor\n \ni\n:=\n0\n;\n \ni\nlen\n(\nslice\n);\ni\n++\n{\n\n        \nif\n \nslice\n[\ni\n]\n \n==\n \nentry\n \n{\n\n            \nreturn\n \ntrue\n\n        \n}\n\n    \n}\n\n    \nreturn\n \nfalse\n\n\n}\n\n\n//Output:\n\n\n//true\n\n\n//false\n\n\n\n\n\n\n\nGet the index of a entry in a slice\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\npackage\n \nmain\n\n\n\nimport\n \nfmt\n\n\n\nfunc\n \nmain\n()\n \n{\n\n    \nletters\n \n:=\n \n[]\nstring\n{\na\n,\n \nb\n,\n \nc\n,\n \nd\n}\n\n    \nfmt\n.\nPrintln\n(\ngetSliceIndex\n(\nletters\n,\n \nc\n))\n\n    \nfmt\n.\nPrintln\n(\ngetSliceIndex\n(\nletters\n,\n \ne\n))\n\n\n}\n\n\n\nfunc\n \ngetSliceIndex\n(\nslice\n \n[]\nstring\n,\n \nentry\n \nstring\n)\n \nint\n{\n\n    \nfor\n \ni\n:=\n0\n;\n \ni\nlen\n(\nslice\n);\ni\n++\n{\n\n        \nif\n \nslice\n[\ni\n]\n \n==\n \nentry\n \n{\n\n            \nreturn\n \ni\n\n        \n}\n\n    \n}\n\n    \nreturn\n \n-\n1\n\n\n}\n\n\n//Output:\n\n\n//2\n\n\n//-1\n\n\n\n\n\n\n\nDelete a entry from a slice\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\npackage\n \nmain\n\n\n\nimport\n \n(\n\n    \nfmt\n\n    \nlog\n\n    \nos\n\n\n)\n\n\n\nfunc\n \nmain\n()\n \n{\n\n    \nletters\n \n:=\n \n[]\nstring\n{\na\n,\n \nb\n,\n \nc\n,\n \nd\n}\n\n    \nfmt\n.\nPrintln\n(\nremoveEntryFromSlice\n(\nletters\n,\n \nc\n))\n\n    \nfmt\n.\nPrintln\n(\nremoveEntryFromSlice\n(\nletters\n,\n \ne\n))\n\n\n}\n\n\n\nfunc\n \ngetSliceIndex\n(\nslice\n \n[]\nstring\n,\n \nentry\n \nstring\n)\n \nint\n{\n\n    \nfor\n \ni\n:=\n0\n;\n \ni\nlen\n(\nslice\n);\ni\n++\n{\n\n        \nif\n \nslice\n[\ni\n]\n \n==\n \nentry\n \n{\n\n            \nreturn\n \ni\n\n        \n}\n\n    \n}\n\n    \nreturn\n \n-\n1\n\n\n}\n\n\n\nfunc\n \nremoveEntryFromSlice\n(\nslice\n \n[]\nstring\n,\n \nentry\n \nstring\n)\n \n[]\nstring\n{\n\n    \ni\n \n:=\n \ngetSliceIndex\n(\nslice\n,\n \nentry\n)\n\n    \nif\n \ni\n \n==\n \n-\n1\n \n{\n\n        \nlog\n.\nPrintf\n(\nThe entry %s does not exist in the array\n,\n \nentry\n)\n\n        \nos\n.\nExit\n(\n1\n)\n\n    \n}\n\n    \nreturn\n \nappend\n(\nslice\n[:\ni\n],\n \nslice\n[\ni\n+\n1\n:]\n...\n)\n\n\n}\n\n\n//Output:\n\n\n//[a b d]\n\n\n//2018/03/20 21:18:42 The entry e does not exist in the array\n\n\n\n\n\n\n\nReference", 
            "title": "Slices in Go"
        }, 
        {
            "location": "/golang/slices/#slices-in-go", 
            "text": "", 
            "title": "Slices in Go"
        }, 
        {
            "location": "/golang/slices/#declaring-a-slice", 
            "text": "1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10 package   main  import   fmt  func   main ()   { \n     letters   :=   [] string { a ,   b ,   c ,   d } \n     fmt . Println ( letters )  }  //Output:   //[a b c d]", 
            "title": "Declaring a slice"
        }, 
        {
            "location": "/golang/slices/#adding-a-entry-to-a-slice", 
            "text": "1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11 package   main  import   fmt  func   main ()   { \n     letters   :=   [] string { a ,   b ,   c ,   d } \n     letters   =   append ( letters ,   e ) \n     fmt . Println ( letters )  }  //Output:   //[a b c d e]", 
            "title": "Adding a entry to a slice"
        }, 
        {
            "location": "/golang/slices/#get-the-length-of-a-slice", 
            "text": "1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12 package   main  import   fmt  func   main ()   { \n     letters   :=   [] string { a ,   b ,   c ,   d } \n     fmt . Println ( letters ) \n     fmt . Println ( Length of the slice is :  ,   len ( letters ))  }  //Output:  //[a b c d]  //Length of the slice is :  4", 
            "title": "Get the length of a slice"
        }, 
        {
            "location": "/golang/slices/#check-if-a-entry-exists-in-a-slice", 
            "text": "1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21 package   main  import   fmt  func   main ()   { \n     letters   :=   [] string { a ,   b ,   c ,   d } \n     fmt . Println ( entryExists ( letters ,   a )) \n     fmt . Println ( entryExists ( letters ,   e ))  }  func   entryExists ( slice   [] string ,   entry   string )   bool { \n     for   i := 0 ;   i len ( slice ); i ++ { \n         if   slice [ i ]   ==   entry   { \n             return   true \n         } \n     } \n     return   false  }  //Output:  //true  //false", 
            "title": "Check if a entry exists in a slice"
        }, 
        {
            "location": "/golang/slices/#get-the-index-of-a-entry-in-a-slice", 
            "text": "1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21 package   main  import   fmt  func   main ()   { \n     letters   :=   [] string { a ,   b ,   c ,   d } \n     fmt . Println ( getSliceIndex ( letters ,   c )) \n     fmt . Println ( getSliceIndex ( letters ,   e ))  }  func   getSliceIndex ( slice   [] string ,   entry   string )   int { \n     for   i := 0 ;   i len ( slice ); i ++ { \n         if   slice [ i ]   ==   entry   { \n             return   i \n         } \n     } \n     return   - 1  }  //Output:  //2  //-1", 
            "title": "Get the index of a entry in a slice"
        }, 
        {
            "location": "/golang/slices/#delete-a-entry-from-a-slice", 
            "text": "1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34 package   main  import   ( \n     fmt \n     log \n     os  )  func   main ()   { \n     letters   :=   [] string { a ,   b ,   c ,   d } \n     fmt . Println ( removeEntryFromSlice ( letters ,   c )) \n     fmt . Println ( removeEntryFromSlice ( letters ,   e ))  }  func   getSliceIndex ( slice   [] string ,   entry   string )   int { \n     for   i := 0 ;   i len ( slice ); i ++ { \n         if   slice [ i ]   ==   entry   { \n             return   i \n         } \n     } \n     return   - 1  }  func   removeEntryFromSlice ( slice   [] string ,   entry   string )   [] string { \n     i   :=   getSliceIndex ( slice ,   entry ) \n     if   i   ==   - 1   { \n         log . Printf ( The entry %s does not exist in the array ,   entry ) \n         os . Exit ( 1 ) \n     } \n     return   append ( slice [: i ],   slice [ i + 1 :] ... )  }  //Output:  //[a b d]  //2018/03/20 21:18:42 The entry e does not exist in the array    Reference", 
            "title": "Delete a entry from a slice"
        }, 
        {
            "location": "/golang/modify-usage-flag/", 
            "text": "Modify Usage flag in go\n\n\nThis can be done by modifying flag.Usage function.\n\n\n1\n2\n3\nflag\n.\nUsage\n \n=\n \nfunc\n()\n \n{\n\n    \nfmt\n.\nFprintf\n(\nos\n.\nStderr\n,\n \nPrint the Usage.\\n\n)\n\n\n}\n\n\n\n\n\n\n\nExample code:\n\n\n 1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\npackage\n \nmain\n\n\n\nimport\n \n(\n\n    \nflag\n\n    \nfmt\n\n    \nos\n\n\n)\n\n\n\nfunc\n \nmain\n()\n \n{\n\n    \nPrintHelp\n()\n\n\n}\n\n\n\nfunc\n \nPrintHelp\n()\n \n{\n\n    \nhelpString\n \n:=\n \n`\n\n\n     Usage: ./nexus-repository-cli.exe [required prameters] [option] [parameters...]\n\n\n\n     [Required Prameters]:\n\n\n     -nexusUrl string\n\n\n         Nexus server URL (default \nhttp://localhost:8081/nexus\n)\n\n\n     -username string\n\n\n            Username for authentication\n\n\n      -password string\n\n\n            Password for authentication\n\n\n\n     [options]\n\n\n      -list\n\n\n            List the repositories in Nexus. Optional parameters: repoType, repoPolicy\n\n\n\n     [parameters]\n\n\n      -repoType string\n\n\n            Type of a repository. Possible values : hosted/proxy/group\n\n\n      -repoPolicy string\n\n\n            Policy of the hosted repository. Possible values : snapshot/release\n\n\n      -verbose\n\n\n            Set this flag for Debug logs.\n\n\n    `\n\n    \nflag\n.\nUsage\n \n=\n \nfunc\n()\n \n{\n\n        \nfmt\n.\nFprintf\n(\nos\n.\nStderr\n,\n \nhelpString\n)\n\n    \n}\n\n    \nflag\n.\nUsage\n()\n\n\n}", 
            "title": "Modify Go Usage flag"
        }, 
        {
            "location": "/golang/modify-usage-flag/#modify-usage-flag-in-go", 
            "text": "This can be done by modifying flag.Usage function.  1\n2\n3 flag . Usage   =   func ()   { \n     fmt . Fprintf ( os . Stderr ,   Print the Usage.\\n )  }    Example code:   1\n 2\n 3\n 4\n 5\n 6\n 7\n 8\n 9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41 package   main  import   ( \n     flag \n     fmt \n     os  )  func   main ()   { \n     PrintHelp ()  }  func   PrintHelp ()   { \n     helpString   :=   `       Usage: ./nexus-repository-cli.exe [required prameters] [option] [parameters...]       [Required Prameters]:       -nexusUrl string           Nexus server URL (default  http://localhost:8081/nexus )       -username string              Username for authentication        -password string              Password for authentication       [options]        -list              List the repositories in Nexus. Optional parameters: repoType, repoPolicy       [parameters]        -repoType string              Type of a repository. Possible values : hosted/proxy/group        -repoPolicy string              Policy of the hosted repository. Possible values : snapshot/release        -verbose              Set this flag for Debug logs.      ` \n     flag . Usage   =   func ()   { \n         fmt . Fprintf ( os . Stderr ,   helpString ) \n     } \n     flag . Usage ()  }", 
            "title": "Modify Usage flag in go"
        }, 
        {
            "location": "/aws/", 
            "text": "Amazon Web Services\n\n\nAmazon Web Services (AWS) is a secure cloud services platform, offering compute power, database storage, content delivery and other functionality to help businesses scale and grow.", 
            "title": "Introduction"
        }, 
        {
            "location": "/aws/#amazon-web-services", 
            "text": "Amazon Web Services (AWS) is a secure cloud services platform, offering compute power, database storage, content delivery and other functionality to help businesses scale and grow.", 
            "title": "Amazon Web Services"
        }, 
        {
            "location": "/blog/cloud-computing/", 
            "text": "What is Cloud Computing?\n\n\nCloud computing is the on-demand delivery of compute power, database storage, applications, and other IT resources through a cloud services platform via the internet with pay-as-you-go pricing.\n\n\nCloud Computing Basics\n\n\nWhether you are running applications that share photos to millions of mobile users or you\u2019re supporting the critical operations of your business, a cloud services platform provides rapid access to flexible and low cost IT resources. With cloud computing, you don\u2019t need to make large upfront investments in hardware and spend a lot of time on the heavy lifting of managing that hardware. Instead, you can provision exactly the right type and size of computing resources you need to power your newest bright idea or operate your IT department. You can access as many resources as you need, almost instantly, and only pay for what you use.\n\n\nHow Does Cloud Computing Work?\n\n\nCloud computing provides a simple way to access servers, storage, databases and a broad set of application services over the Internet. A Cloud services platform such as Amazon Web Services owns and maintains the network-connected hardware required for these application services, while you provision and use what you need via a web application.\n\n\nAdvantages of cloud computing\n\n\nTrade capital expense for variable expense\n\n\nInstead of having to invest heavily in data centers and servers before you know how you\u2019re going to use them, you can only pay when you consume computing resources, and only pay for how much you consume.\n\n\nBenefit from massive economies of scale\n\n\nBy using cloud computing, you can achieve a lower variable cost than you can get on your own. Because usage from hundreds of thousands of customers are aggregated in the cloud, providers such as Amazon Web Services can achieve higher economies of scale which translates into lower pay as you go prices.\n\n\nStop guessing capacity\n\n\nEliminate guessing on your infrastructure capacity needs. When you make a capacity decision prior to deploying an application, you often either end up sitting on expensive idle resources or dealing with limited capacity. With cloud computing, these problems go away. You can access as much or as little as you need, and scale up and down as required with only a few minutes notice.\n\n\nIncrease speed and agility\n\n\nIn a cloud computing environment, new IT resources are only ever a click away, which means you reduce the time it takes to make those resources available to your developers from weeks to just minutes. This results in a dramatic increase in agility for the organization, since the cost and time it takes to experiment and develop is significantly lower.\n\n\nStop spending money on running and maintaining data centers\n\n\nFocus on projects that differentiate your business, not the infrastructure. Cloud computing lets you focus on your own customers, rather than on the heavy lifting of racking, stacking and powering servers.\n\n\nGo global in minutes\n\n\nEasily deploy your application in multiple regions around the world with just a few clicks. This means you can provide a lower latency and better experience for your customers simply and at minimal cost.", 
            "title": "Cloud Computing"
        }, 
        {
            "location": "/blog/cloud-computing/#what-is-cloud-computing", 
            "text": "Cloud computing is the on-demand delivery of compute power, database storage, applications, and other IT resources through a cloud services platform via the internet with pay-as-you-go pricing.", 
            "title": "What is Cloud Computing?"
        }, 
        {
            "location": "/blog/cloud-computing/#cloud-computing-basics", 
            "text": "Whether you are running applications that share photos to millions of mobile users or you\u2019re supporting the critical operations of your business, a cloud services platform provides rapid access to flexible and low cost IT resources. With cloud computing, you don\u2019t need to make large upfront investments in hardware and spend a lot of time on the heavy lifting of managing that hardware. Instead, you can provision exactly the right type and size of computing resources you need to power your newest bright idea or operate your IT department. You can access as many resources as you need, almost instantly, and only pay for what you use.", 
            "title": "Cloud Computing Basics"
        }, 
        {
            "location": "/blog/cloud-computing/#how-does-cloud-computing-work", 
            "text": "Cloud computing provides a simple way to access servers, storage, databases and a broad set of application services over the Internet. A Cloud services platform such as Amazon Web Services owns and maintains the network-connected hardware required for these application services, while you provision and use what you need via a web application.", 
            "title": "How Does Cloud Computing Work?"
        }, 
        {
            "location": "/blog/cloud-computing/#advantages-of-cloud-computing", 
            "text": "", 
            "title": "Advantages of cloud computing"
        }, 
        {
            "location": "/blog/cloud-computing/#trade-capital-expense-for-variable-expense", 
            "text": "Instead of having to invest heavily in data centers and servers before you know how you\u2019re going to use them, you can only pay when you consume computing resources, and only pay for how much you consume.", 
            "title": "Trade capital expense for variable expense"
        }, 
        {
            "location": "/blog/cloud-computing/#benefit-from-massive-economies-of-scale", 
            "text": "By using cloud computing, you can achieve a lower variable cost than you can get on your own. Because usage from hundreds of thousands of customers are aggregated in the cloud, providers such as Amazon Web Services can achieve higher economies of scale which translates into lower pay as you go prices.", 
            "title": "Benefit from massive economies of scale"
        }, 
        {
            "location": "/blog/cloud-computing/#stop-guessing-capacity", 
            "text": "Eliminate guessing on your infrastructure capacity needs. When you make a capacity decision prior to deploying an application, you often either end up sitting on expensive idle resources or dealing with limited capacity. With cloud computing, these problems go away. You can access as much or as little as you need, and scale up and down as required with only a few minutes notice.", 
            "title": "Stop guessing capacity"
        }, 
        {
            "location": "/blog/cloud-computing/#increase-speed-and-agility", 
            "text": "In a cloud computing environment, new IT resources are only ever a click away, which means you reduce the time it takes to make those resources available to your developers from weeks to just minutes. This results in a dramatic increase in agility for the organization, since the cost and time it takes to experiment and develop is significantly lower.", 
            "title": "Increase speed and agility"
        }, 
        {
            "location": "/blog/cloud-computing/#stop-spending-money-on-running-and-maintaining-data-centers", 
            "text": "Focus on projects that differentiate your business, not the infrastructure. Cloud computing lets you focus on your own customers, rather than on the heavy lifting of racking, stacking and powering servers.", 
            "title": "Stop spending money on running and maintaining data centers"
        }, 
        {
            "location": "/blog/cloud-computing/#go-global-in-minutes", 
            "text": "Easily deploy your application in multiple regions around the world with just a few clicks. This means you can provide a lower latency and better experience for your customers simply and at minimal cost.", 
            "title": "Go global in minutes"
        }, 
        {
            "location": "/aws/global-infrastructure/", 
            "text": "AWS Global Infrastructure\n\n\nUnderstanding the difference between a region, an Availabity Zone (AZ) and an Edge Location\n\n\nRegion\n\n\n\n\nA region is a physical location in the world which consists of two or more Availability Zones.\n\n\nA AWS region consists of an independent collection of AWS computing resources in a defined geography.\n\n\n\n\nAvailability Zones\n\n\n\n\nAn Availability Zone is one or more discrete data centers, each with redundant power, networking and connectivity, housed in separate facilities.\n\n\nAvalability zones are distinct locations from within a AWS region that are engineered to be isolated from failures.\n\n\n\n\nEdge Locations\n\n\n\n\nEdge locations are endpoints for AWS which are used for cacheing content. Typically it consists of CloudFront which is Amazon's Content Delivery Network (CDN)", 
            "title": "Global Infrastructure"
        }, 
        {
            "location": "/aws/global-infrastructure/#aws-global-infrastructure", 
            "text": "", 
            "title": "AWS Global Infrastructure"
        }, 
        {
            "location": "/aws/global-infrastructure/#understanding-the-difference-between-a-region-an-availabity-zone-az-and-an-edge-location", 
            "text": "", 
            "title": "Understanding the difference between a region, an Availabity Zone (AZ) and an Edge Location"
        }, 
        {
            "location": "/aws/global-infrastructure/#region", 
            "text": "A region is a physical location in the world which consists of two or more Availability Zones.  A AWS region consists of an independent collection of AWS computing resources in a defined geography.", 
            "title": "Region"
        }, 
        {
            "location": "/aws/global-infrastructure/#availability-zones", 
            "text": "An Availability Zone is one or more discrete data centers, each with redundant power, networking and connectivity, housed in separate facilities.  Avalability zones are distinct locations from within a AWS region that are engineered to be isolated from failures.", 
            "title": "Availability Zones"
        }, 
        {
            "location": "/aws/global-infrastructure/#edge-locations", 
            "text": "Edge locations are endpoints for AWS which are used for cacheing content. Typically it consists of CloudFront which is Amazon's Content Delivery Network (CDN)", 
            "title": "Edge Locations"
        }, 
        {
            "location": "/aws/services/security-identity-compliance/", 
            "text": "Security, Identity and Compliance\n\n\nIAM [Identity and Access management]\n\n\nEssentially, IAM allows you to manage users and their level of access to the AWS console.\n\n\nWhat does IAM give you?\n\n\n\n\nCentralised control of your AWS account\n\n\nShared access to your AWS account\n\n\nGranular permissions\n\n\nIdentity Federation\n\n\nMultifactor Authentication\n\n\nProvide temporary access for users/devices and services where necessary\n\n\nAllows you ti set up your own password rotation policy\n\n\nSupports PCI DSS Compliance\n\n\n\n\nCrtical terms:\n\n\nUsers - End Users\n\n\nGroups- A collection of users under one set of permissions\n\n\nRoles - You create roles and can then assign them to AWS resources\n\n\nPolicies - A document that defines one or more permission. Attach to users, group or a role.\nPolicy documents are writen in JSON language.\n\n\nRoot account\n\n\nRoot account is simply the email ID you use to sing-up to the AWS account. Root account gives you unlimited amount of access to the AWS account.\n\n\nNew Users\n\n\nNew users have no access when first created.\nNew users are assigned Access Key ID and Secret access Keys when first created and a password for login in to the aws console. The credentials can only be viewed once and cannot be retrieved later.\nIf lost they will have to be generated again.\nThese are not same as a password, and you cannot use the Access key ID and the Secret access Ket to login to the AWS console.\nYou can use this to access AWS via the APIs and Command line.\nUsername and password cannot be used to access AWS via the API.\n\n\nAlways setup MFA (Multifactor Authentication) on your root account.\n\n\nYou can create and customise your own password policies and password rotation polices.\n\n\nIAM is universal. It does not apply to regions at this time.\n\n\nPower users\n\n\nProvides full access to AWS services and resources, but does not allow management of Users and groups.\n\n\nCognito\n\n\nIs a way of doing device authentication.Authenticate using FB, google etc.\n\n\nUse Cognito as a authentication service to get temporary access to certain AWS resources.\n\n\nGuardDuty\n\n\nIt monitors for malicious activities on your AWS environment.\n\n\nInspector\n\n\nInstalled on Virtual machines and EC2 instances to run a whole bunch of tests agains it to check for security vulnerabilities.\n\n\nCan be scheduled to run weekly, monthly, etc.\n\n\nGenerates a report and gives you a severity report of the vulnerabilities.\n\n\nMacie\n\n\nWill scan your s3 bucket to look for information that contain a personally identifiable information PII like names, adresses, passport numbers etc and alert you.\n\n\nCertificate Manager\n\n\nGet ssl certificates for free if your using AWS services and registering the domains through route 53.\n\n\nFor Managing SSL certificates.\n\n\nCloudHSM \u2013 Secure Key Storage and Cryptographic Operations\n\n\nHSM is short for Hardware Security Module. It is a piece of hardware \u2014 a dedicated appliance that provides secure key storage and a set of cryptographic operations within a tamper-resistant enclosure. You can store your keys within an HSM and use them to encrypt and decrypt data while keeping them safe and sound and under your full control. You are the only one with access to the keys stored in an HSM.\n\n\nEach of your CloudHSMs has an IP address within your Amazon Virtual Private Cloud (VPC). You\u2019ll receive administrator credentials for the appliance, allowing you to create and manage cryptographic keys, create user accounts, and perform cryptographic operations using those accounts. We do not have access to your keys; they remain under your control at all times. In Luna SA terminology, we have Admin credentials and you have both HSM Admin and HSM Partition Owner credentials.\n\n\nDedicated bits of hardware used to store your keys eg: private and public keys.\n\n\nThe keys may be used to access your EC2 instances. Can used these keys to encrypy AWS objects.\n\n\nDirectory Service\n\n\nA way of integration AD with AWS services.\n\n\nWAF : Web Application Firewall\n\n\nPrevents cross site scripting, SQL injections etc. Prevents malicious users.\n\n\nShield\n\n\nShield is basically DDOS mitigation.\n\n\nArtifact\n\n\nFor Audit and compliance. Way of downloading and inspecting Amazons documentations.", 
            "title": "Security, Identity and Compliance"
        }, 
        {
            "location": "/aws/services/security-identity-compliance/#security-identity-and-compliance", 
            "text": "", 
            "title": "Security, Identity and Compliance"
        }, 
        {
            "location": "/aws/services/security-identity-compliance/#iam-identity-and-access-management", 
            "text": "Essentially, IAM allows you to manage users and their level of access to the AWS console.  What does IAM give you?   Centralised control of your AWS account  Shared access to your AWS account  Granular permissions  Identity Federation  Multifactor Authentication  Provide temporary access for users/devices and services where necessary  Allows you ti set up your own password rotation policy  Supports PCI DSS Compliance   Crtical terms:  Users - End Users  Groups- A collection of users under one set of permissions  Roles - You create roles and can then assign them to AWS resources  Policies - A document that defines one or more permission. Attach to users, group or a role.\nPolicy documents are writen in JSON language.  Root account  Root account is simply the email ID you use to sing-up to the AWS account. Root account gives you unlimited amount of access to the AWS account.  New Users  New users have no access when first created.\nNew users are assigned Access Key ID and Secret access Keys when first created and a password for login in to the aws console. The credentials can only be viewed once and cannot be retrieved later.\nIf lost they will have to be generated again.\nThese are not same as a password, and you cannot use the Access key ID and the Secret access Ket to login to the AWS console.\nYou can use this to access AWS via the APIs and Command line.\nUsername and password cannot be used to access AWS via the API.  Always setup MFA (Multifactor Authentication) on your root account.  You can create and customise your own password policies and password rotation polices.  IAM is universal. It does not apply to regions at this time.  Power users  Provides full access to AWS services and resources, but does not allow management of Users and groups.", 
            "title": "IAM [Identity and Access management]"
        }, 
        {
            "location": "/aws/services/security-identity-compliance/#cognito", 
            "text": "Is a way of doing device authentication.Authenticate using FB, google etc.  Use Cognito as a authentication service to get temporary access to certain AWS resources.", 
            "title": "Cognito"
        }, 
        {
            "location": "/aws/services/security-identity-compliance/#guardduty", 
            "text": "It monitors for malicious activities on your AWS environment.", 
            "title": "GuardDuty"
        }, 
        {
            "location": "/aws/services/security-identity-compliance/#inspector", 
            "text": "Installed on Virtual machines and EC2 instances to run a whole bunch of tests agains it to check for security vulnerabilities.  Can be scheduled to run weekly, monthly, etc.  Generates a report and gives you a severity report of the vulnerabilities.", 
            "title": "Inspector"
        }, 
        {
            "location": "/aws/services/security-identity-compliance/#macie", 
            "text": "Will scan your s3 bucket to look for information that contain a personally identifiable information PII like names, adresses, passport numbers etc and alert you.", 
            "title": "Macie"
        }, 
        {
            "location": "/aws/services/security-identity-compliance/#certificate-manager", 
            "text": "Get ssl certificates for free if your using AWS services and registering the domains through route 53.  For Managing SSL certificates.", 
            "title": "Certificate Manager"
        }, 
        {
            "location": "/aws/services/security-identity-compliance/#cloudhsm-secure-key-storage-and-cryptographic-operations", 
            "text": "HSM is short for Hardware Security Module. It is a piece of hardware \u2014 a dedicated appliance that provides secure key storage and a set of cryptographic operations within a tamper-resistant enclosure. You can store your keys within an HSM and use them to encrypt and decrypt data while keeping them safe and sound and under your full control. You are the only one with access to the keys stored in an HSM.  Each of your CloudHSMs has an IP address within your Amazon Virtual Private Cloud (VPC). You\u2019ll receive administrator credentials for the appliance, allowing you to create and manage cryptographic keys, create user accounts, and perform cryptographic operations using those accounts. We do not have access to your keys; they remain under your control at all times. In Luna SA terminology, we have Admin credentials and you have both HSM Admin and HSM Partition Owner credentials.  Dedicated bits of hardware used to store your keys eg: private and public keys.  The keys may be used to access your EC2 instances. Can used these keys to encrypy AWS objects.", 
            "title": "CloudHSM \u2013 Secure Key Storage and Cryptographic Operations"
        }, 
        {
            "location": "/aws/services/security-identity-compliance/#directory-service", 
            "text": "A way of integration AD with AWS services.", 
            "title": "Directory Service"
        }, 
        {
            "location": "/aws/services/security-identity-compliance/#waf-web-application-firewall", 
            "text": "Prevents cross site scripting, SQL injections etc. Prevents malicious users.", 
            "title": "WAF : Web Application Firewall"
        }, 
        {
            "location": "/aws/services/security-identity-compliance/#shield", 
            "text": "Shield is basically DDOS mitigation.", 
            "title": "Shield"
        }, 
        {
            "location": "/aws/services/security-identity-compliance/#artifact", 
            "text": "For Audit and compliance. Way of downloading and inspecting Amazons documentations.", 
            "title": "Artifact"
        }, 
        {
            "location": "/aws/services/compute/", 
            "text": "Compute\n\n\nEC2 : Elastic Compute Cloud\n\n\nVirtual servers inside the AWS platform\n\n\nAmazon Elastic Compute Cloud (Amazon EC2) provides scalable computing capacity in the Amazon Web Services (AWS) cloud. Using Amazon EC2 eliminates your need to invest in hardware up front, so you can develop and deploy applications faster. You can use Amazon EC2 to launch as many or as few virtual servers as you need, configure security and networking, and manage storage. Amazon EC2 enables you to scale up or down to handle changes in requirements or spikes in popularity, reducing your need to forecast traffic.\n\n\nFeatures of Amazon EC2\n\n\nAmazon EC2 provides the following features:\n\n\nVirtual computing environments, known as instances\n\n\n\n\nPreconfigured templates for your instances, known as Amazon Machine Images (AMIs), that package the bits you need for your server (including the operating system and additional software)\n\n\nVarious configurations of CPU, memory, storage, and networking capacity for your instances, known as instance types\n\n\nSecure login information for your instances using key pairs (AWS stores the public key, and you store the private key in a secure place)\n\n\nStorage volumes for temporary data that's deleted when you stop or terminate your instance, known as instance store volumes\n\n\nPersistent storage volumes for your data using Amazon Elastic Block Store (Amazon EBS), known as Amazon EBS volumes\n\n\nMultiple physical locations for your resources, such as instances and Amazon EBS volumes, known as regions and Availability Zones\n\n\nA firewall that enables you to specify the protocols, ports, and source IP ranges that can reach your instances using security groups\n\n\nStatic IPv4 addresses for dynamic cloud computing, known as Elastic IP addresses\n\n\nMetadata, known as tags, that you can create and assign to your Amazon EC2 resources\n\n\nVirtual networks you can create that are logically isolated from the rest of the AWS cloud, and that you can optionally connect to your own network, known as virtual private clouds (VPCs)\n\n\n\n\nECS : Elastic Container Services\n\n\nRun and manage docker containers\n\n\nAmazon Elastic Container Service (Amazon ECS) is a highly scalable, fast, container management service that makes it easy to run, stop, and manage Docker containers on a cluster. \n\n\nYou can host your cluster on a serverless infrastructure that is managed by Amazon ECS by launching your services or tasks using the Fargate launch type.\n\n\nEC2 Auto Scaling\n\n\nScale compute capacity to meet demands\n\n\nAWS Auto Scaling monitors your applications and automatically adjusts capacity to maintain steady, predictable performance at the lowest possible cost. \n\n\nUsing AWS Auto Scaling, you can setup scaling for multiple resources across multiple services in minutes. AWS Auto Scaling provides a simple, powerful user interface that lets you build scaling plans for Amazon EC2 instances\n\n\nElastic Beanstalk\n\n\nAmazon Web Services (AWS) comprises dozens of services, each of which exposes an area of functionality. While the variety of services offers flexibility for how you want to manage your AWS infrastructure, it can be challenging to figure out which services to use and how to provision them.\n\n\nWith Elastic Beanstalk, you can quickly deploy and manage applications in the AWS Cloud without worrying about the infrastructure that runs those applications. AWS Elastic Beanstalk reduces management complexity without restricting choice or control. You simply upload your application, and Elastic Beanstalk automatically handles the details of capacity provisioning, load balancing, scaling, and application health monitoring.\n\n\nFor people who do not want to understand how AWS works and only care about the functioning of their application.\n\n\nLambda\n\n\nRun you code in response to events.\n\n\nLightsail\n\n\nLaunch and manage virtual private servers (VPS).\n\n\nFor people who dont want to understand AWS and the underlying infrastructure. They dont want to know about VPC's and security groups.\n\n\nThis service will just provision you with a server, A fixed IP addrres for login and you can start working on it.\n\n\nComes with a management console for managing the server.\n\n\nBatch\n\n\nRun batch jobs at any scale.\nBatch computing on the cloud.", 
            "title": "Compute"
        }, 
        {
            "location": "/aws/services/compute/#compute", 
            "text": "", 
            "title": "Compute"
        }, 
        {
            "location": "/aws/services/compute/#ec2-elastic-compute-cloud", 
            "text": "Virtual servers inside the AWS platform  Amazon Elastic Compute Cloud (Amazon EC2) provides scalable computing capacity in the Amazon Web Services (AWS) cloud. Using Amazon EC2 eliminates your need to invest in hardware up front, so you can develop and deploy applications faster. You can use Amazon EC2 to launch as many or as few virtual servers as you need, configure security and networking, and manage storage. Amazon EC2 enables you to scale up or down to handle changes in requirements or spikes in popularity, reducing your need to forecast traffic.", 
            "title": "EC2 : Elastic Compute Cloud"
        }, 
        {
            "location": "/aws/services/compute/#features-of-amazon-ec2", 
            "text": "Amazon EC2 provides the following features:  Virtual computing environments, known as instances   Preconfigured templates for your instances, known as Amazon Machine Images (AMIs), that package the bits you need for your server (including the operating system and additional software)  Various configurations of CPU, memory, storage, and networking capacity for your instances, known as instance types  Secure login information for your instances using key pairs (AWS stores the public key, and you store the private key in a secure place)  Storage volumes for temporary data that's deleted when you stop or terminate your instance, known as instance store volumes  Persistent storage volumes for your data using Amazon Elastic Block Store (Amazon EBS), known as Amazon EBS volumes  Multiple physical locations for your resources, such as instances and Amazon EBS volumes, known as regions and Availability Zones  A firewall that enables you to specify the protocols, ports, and source IP ranges that can reach your instances using security groups  Static IPv4 addresses for dynamic cloud computing, known as Elastic IP addresses  Metadata, known as tags, that you can create and assign to your Amazon EC2 resources  Virtual networks you can create that are logically isolated from the rest of the AWS cloud, and that you can optionally connect to your own network, known as virtual private clouds (VPCs)", 
            "title": "Features of Amazon EC2"
        }, 
        {
            "location": "/aws/services/compute/#ecs-elastic-container-services", 
            "text": "Run and manage docker containers  Amazon Elastic Container Service (Amazon ECS) is a highly scalable, fast, container management service that makes it easy to run, stop, and manage Docker containers on a cluster.   You can host your cluster on a serverless infrastructure that is managed by Amazon ECS by launching your services or tasks using the Fargate launch type.", 
            "title": "ECS : Elastic Container Services"
        }, 
        {
            "location": "/aws/services/compute/#ec2-auto-scaling", 
            "text": "Scale compute capacity to meet demands  AWS Auto Scaling monitors your applications and automatically adjusts capacity to maintain steady, predictable performance at the lowest possible cost.   Using AWS Auto Scaling, you can setup scaling for multiple resources across multiple services in minutes. AWS Auto Scaling provides a simple, powerful user interface that lets you build scaling plans for Amazon EC2 instances", 
            "title": "EC2 Auto Scaling"
        }, 
        {
            "location": "/aws/services/compute/#elastic-beanstalk", 
            "text": "Amazon Web Services (AWS) comprises dozens of services, each of which exposes an area of functionality. While the variety of services offers flexibility for how you want to manage your AWS infrastructure, it can be challenging to figure out which services to use and how to provision them.  With Elastic Beanstalk, you can quickly deploy and manage applications in the AWS Cloud without worrying about the infrastructure that runs those applications. AWS Elastic Beanstalk reduces management complexity without restricting choice or control. You simply upload your application, and Elastic Beanstalk automatically handles the details of capacity provisioning, load balancing, scaling, and application health monitoring.  For people who do not want to understand how AWS works and only care about the functioning of their application.", 
            "title": "Elastic Beanstalk"
        }, 
        {
            "location": "/aws/services/compute/#lambda", 
            "text": "Run you code in response to events.", 
            "title": "Lambda"
        }, 
        {
            "location": "/aws/services/compute/#lightsail", 
            "text": "Launch and manage virtual private servers (VPS).  For people who dont want to understand AWS and the underlying infrastructure. They dont want to know about VPC's and security groups.  This service will just provision you with a server, A fixed IP addrres for login and you can start working on it.  Comes with a management console for managing the server.", 
            "title": "Lightsail"
        }, 
        {
            "location": "/aws/services/compute/#batch", 
            "text": "Run batch jobs at any scale.\nBatch computing on the cloud.", 
            "title": "Batch"
        }, 
        {
            "location": "/aws/services/storage/", 
            "text": "Storage\n\n\nS3 [Simple storage service]\n\n\nAmazon S3 provides access to reliable, fast, and inexpensive data storage infrastructure.\n\n\nOne of the oldest storage service on AWS.\n\n\nS3 Basics\n\n\nS3 is a safe place to store your files.\nIt is a object based storage i.e. it allows you to upload files. Example: text files, videos, images, word files etc.\nThe data is spread across multiple devices and facilities.\nFiles can be from 0 Bytes to 5 TB.\nThere is unlimited storage.\nFiles are stores in buckets.\nS3 is a universal namespace, that is, names must be globally unique.\nWhen you upload a file to S3 you will receive a HTTP 200 code if the upload was successful.\nBuilt for 99.99% availability.\nSupports versioning.\nSupports encryption.\nData can be secured using Access Control Lists and Bucket Policies.\n\n\nData consistency Model\n\n\nRead after Write consistency for PUTS of new Objects. You will be able to read the data as soon as you upload it.\n\n\nEventual Consistency for overwrite PUTS and DELETES (can take some time to propagate). Thus if you try to read updated data you either get the new data or the old data but the data is never currupted or incosistent.\n\n\nS3 is a simple key, value store\n\n\nS3 is Object based and Objects consists of the following:\n    Key : The name of the object\n    Value : The data which is made up of a sequence of bytes.\n    Version ID : for versioning\n    Metadata : Data about the data you are storing\n    Subresources\n        Access Control list : Who can access this object. Allows you to do fine grain permission.\n        Torrent : Support for bit torrect protocol\n\n\nStorage Tiers/Classes\n\n\nS3\n\n\n99.99% availability, 99.(11 x 9's)% durability, stored redundantly across multiple devices in multiple facilities and is designed to sustain the loss of 2 facilities concurrently.\n\n\nS3 - IA (Infrequently Accessed)\n\n\nFor data that is accessed less frequently, but requires rapid access when needed. Lower fee than the S3, but you are charged a retrieval fee (Per GB retrieved).\n\n\nReduced Redency Storage\n\n\nDesigned to provide 99.99% availability and 99.99% durability of objects over a given year. Thus durability less that the S3 but cost much lower than the S3.\nImages and thumbnail example. \nTo keep files that can be regenerated.\n\n\nGlacier\n\n\nGlacier is an extremely low-cost storage service and only costs $0.01 per gigabyte per month, abd is optimised for data that is infrequently accessed and for which retrieval times of 3 - 5 hours are suitable.\n\n\nEFS [Elastic file system]\n\n\nAmazon EFS provides scalable file storage for use with Amazon EC2. You can create an EFS file system and configure your instances to mount the file system. You can use an EFS file system as a common data source for workloads and applications running on multiple instances.\n\n\nBasically Network Attached storage. Can mount them to multiple virtual machines.\n\n\nGlacier\n\n\nFor data archieving.\n\n\nSnowball\n\n\nMove GB's of data to the Amazon data center without using broadband line or wifi. Write it phisically to a disk which is then moved to the data center of AWS.\n\n\nStorage gateway\n\n\nAWS Storage Gateway is a hybrid storage service that enables your on-premises applications to seamlessly use AWS cloud storage. You can use the service for backup and archiving, disaster recovery, cloud bursting, storage tiering, and migration. Your applications connect to the service through a gateway appliance using standard storage protocols, such as NFS and iSCSI.", 
            "title": "Storage"
        }, 
        {
            "location": "/aws/services/storage/#storage", 
            "text": "", 
            "title": "Storage"
        }, 
        {
            "location": "/aws/services/storage/#s3-simple-storage-service", 
            "text": "Amazon S3 provides access to reliable, fast, and inexpensive data storage infrastructure.  One of the oldest storage service on AWS.  S3 Basics  S3 is a safe place to store your files.\nIt is a object based storage i.e. it allows you to upload files. Example: text files, videos, images, word files etc.\nThe data is spread across multiple devices and facilities.\nFiles can be from 0 Bytes to 5 TB.\nThere is unlimited storage.\nFiles are stores in buckets.\nS3 is a universal namespace, that is, names must be globally unique.\nWhen you upload a file to S3 you will receive a HTTP 200 code if the upload was successful.\nBuilt for 99.99% availability.\nSupports versioning.\nSupports encryption.\nData can be secured using Access Control Lists and Bucket Policies.  Data consistency Model  Read after Write consistency for PUTS of new Objects. You will be able to read the data as soon as you upload it.  Eventual Consistency for overwrite PUTS and DELETES (can take some time to propagate). Thus if you try to read updated data you either get the new data or the old data but the data is never currupted or incosistent.  S3 is a simple key, value store  S3 is Object based and Objects consists of the following:\n    Key : The name of the object\n    Value : The data which is made up of a sequence of bytes.\n    Version ID : for versioning\n    Metadata : Data about the data you are storing\n    Subresources\n        Access Control list : Who can access this object. Allows you to do fine grain permission.\n        Torrent : Support for bit torrect protocol  Storage Tiers/Classes  S3  99.99% availability, 99.(11 x 9's)% durability, stored redundantly across multiple devices in multiple facilities and is designed to sustain the loss of 2 facilities concurrently.  S3 - IA (Infrequently Accessed)  For data that is accessed less frequently, but requires rapid access when needed. Lower fee than the S3, but you are charged a retrieval fee (Per GB retrieved).  Reduced Redency Storage  Designed to provide 99.99% availability and 99.99% durability of objects over a given year. Thus durability less that the S3 but cost much lower than the S3.\nImages and thumbnail example. \nTo keep files that can be regenerated.  Glacier  Glacier is an extremely low-cost storage service and only costs $0.01 per gigabyte per month, abd is optimised for data that is infrequently accessed and for which retrieval times of 3 - 5 hours are suitable.", 
            "title": "S3 [Simple storage service]"
        }, 
        {
            "location": "/aws/services/storage/#efs-elastic-file-system", 
            "text": "Amazon EFS provides scalable file storage for use with Amazon EC2. You can create an EFS file system and configure your instances to mount the file system. You can use an EFS file system as a common data source for workloads and applications running on multiple instances.  Basically Network Attached storage. Can mount them to multiple virtual machines.", 
            "title": "EFS [Elastic file system]"
        }, 
        {
            "location": "/aws/services/storage/#glacier", 
            "text": "For data archieving.", 
            "title": "Glacier"
        }, 
        {
            "location": "/aws/services/storage/#snowball", 
            "text": "Move GB's of data to the Amazon data center without using broadband line or wifi. Write it phisically to a disk which is then moved to the data center of AWS.", 
            "title": "Snowball"
        }, 
        {
            "location": "/aws/services/storage/#storage-gateway", 
            "text": "AWS Storage Gateway is a hybrid storage service that enables your on-premises applications to seamlessly use AWS cloud storage. You can use the service for backup and archiving, disaster recovery, cloud bursting, storage tiering, and migration. Your applications connect to the service through a gateway appliance using standard storage protocols, such as NFS and iSCSI.", 
            "title": "Storage gateway"
        }, 
        {
            "location": "/aws/services/database/", 
            "text": "Database\n\n\nRDS : Relation database service\n\n\nAmazon Relational Database Service (Amazon RDS) makes it easy to set up, operate, and scale a relational database in the cloud. It provides cost-efficient and resizable capacity while automating time-consuming administration tasks such as hardware provisioning, database setup, patching and backups.\n\n\nAmazon RDS is available on several database instance types - optimized for memory, performance or I/O - and provides you with six familiar database engines to choose from, including Amazon Aurora, PostgreSQL, MySQL, MariaDB, Oracle, and Microsoft SQL Server. You can use the AWS Database Migration Service to easily migrate or replicate your existing databases to Amazon RDS.\n\n\nDynamo DB\n\n\nNon relational db (will be covered later)\n\n\nElasticache\n\n\nFor caching commonly executed queries.\n\n\nAmazon ElastiCache offers fully managed Redis and Memcached. Seamlessly deploy, operate, and scale popular open source compatible in-memory data stores. Build data-intensive apps or improve the performance of your existing apps by retrieving data from high throughput and low latency in-memory data stores. Amazon ElastiCache is a popular choice for Gaming, Ad-Tech, Financial Services, Healthcare, and IoT apps.\n\n\nRedshift\n\n\nFor data warehousing and business intelligence.", 
            "title": "Database"
        }, 
        {
            "location": "/aws/services/database/#database", 
            "text": "", 
            "title": "Database"
        }, 
        {
            "location": "/aws/services/database/#rds-relation-database-service", 
            "text": "Amazon Relational Database Service (Amazon RDS) makes it easy to set up, operate, and scale a relational database in the cloud. It provides cost-efficient and resizable capacity while automating time-consuming administration tasks such as hardware provisioning, database setup, patching and backups.  Amazon RDS is available on several database instance types - optimized for memory, performance or I/O - and provides you with six familiar database engines to choose from, including Amazon Aurora, PostgreSQL, MySQL, MariaDB, Oracle, and Microsoft SQL Server. You can use the AWS Database Migration Service to easily migrate or replicate your existing databases to Amazon RDS.", 
            "title": "RDS : Relation database service"
        }, 
        {
            "location": "/aws/services/database/#dynamo-db", 
            "text": "Non relational db (will be covered later)", 
            "title": "Dynamo DB"
        }, 
        {
            "location": "/aws/services/database/#elasticache", 
            "text": "For caching commonly executed queries.  Amazon ElastiCache offers fully managed Redis and Memcached. Seamlessly deploy, operate, and scale popular open source compatible in-memory data stores. Build data-intensive apps or improve the performance of your existing apps by retrieving data from high throughput and low latency in-memory data stores. Amazon ElastiCache is a popular choice for Gaming, Ad-Tech, Financial Services, Healthcare, and IoT apps.", 
            "title": "Elasticache"
        }, 
        {
            "location": "/aws/services/database/#redshift", 
            "text": "For data warehousing and business intelligence.", 
            "title": "Redshift"
        }, 
        {
            "location": "/aws/services/migration/", 
            "text": "Migration\n\n\nAWS migration hub\n\n\nAllows you to track you applications as you move your application to AWS and will integrate with other services of the migration framework.\n\n\nFor visualizing the progress of your migrations.\n\n\nApplication discovery  service\n\n\nDetects the applications you have along with their depencies. For example if you have a sonarqube server it may have a dependency on a sql server or a domain controller. Thus its a way of tracking dependencies for your application.\n\n\nDatabase Migration service\n\n\nVery easy way to migrate on premise databases to AWS.\n\n\nServer migration service\n\n\nHelps you to migrate your virtual or physical server to the AWS cloud.\n\n\nSnowball\n\n\nHelps you to phusically migrate large chunks of data into the cloud.", 
            "title": "Migration"
        }, 
        {
            "location": "/aws/services/migration/#migration", 
            "text": "", 
            "title": "Migration"
        }, 
        {
            "location": "/aws/services/migration/#aws-migration-hub", 
            "text": "Allows you to track you applications as you move your application to AWS and will integrate with other services of the migration framework.  For visualizing the progress of your migrations.", 
            "title": "AWS migration hub"
        }, 
        {
            "location": "/aws/services/migration/#application-discovery-service", 
            "text": "Detects the applications you have along with their depencies. For example if you have a sonarqube server it may have a dependency on a sql server or a domain controller. Thus its a way of tracking dependencies for your application.", 
            "title": "Application discovery  service"
        }, 
        {
            "location": "/aws/services/migration/#database-migration-service", 
            "text": "Very easy way to migrate on premise databases to AWS.", 
            "title": "Database Migration service"
        }, 
        {
            "location": "/aws/services/migration/#server-migration-service", 
            "text": "Helps you to migrate your virtual or physical server to the AWS cloud.", 
            "title": "Server migration service"
        }, 
        {
            "location": "/aws/services/migration/#snowball", 
            "text": "Helps you to phusically migrate large chunks of data into the cloud.", 
            "title": "Snowball"
        }, 
        {
            "location": "/aws/services/networking-and-content-delivery/", 
            "text": "Networking and content delivery\n\n\nVPC : Virtual Private Cloud\n\n\nAmazon Virtual private cloud. Can be considered as a virtual datacenter.\n\n\nAmazon Virtual Private Cloud (Amazon VPC) enables you to launch AWS resources into a virtual network that you've defined. This virtual network closely resembles a traditional network that you'd operate in your own data center, with the benefits of using the scalable infrastructure of AWS.\n\n\nConfigure firewall, availability zones, network sider address ranges,  Network ACL's, route tables etc.\n\n\nCloudFront\n\n\nAmazons content delivery network service.\n\n\nRoute 53\n\n\nAmazons DNS service.\n\n\nAPI Gateway\n\n\nFor creating a serverless website.\n\n\nA way of creating your own API for other services to talk to.\n\n\nDirect connect\n\n\nIs a way of running a dedicated line from your Corporate head office or data center to AWS.", 
            "title": "Networking and Content Delivery"
        }, 
        {
            "location": "/aws/services/networking-and-content-delivery/#networking-and-content-delivery", 
            "text": "", 
            "title": "Networking and content delivery"
        }, 
        {
            "location": "/aws/services/networking-and-content-delivery/#vpc-virtual-private-cloud", 
            "text": "Amazon Virtual private cloud. Can be considered as a virtual datacenter.  Amazon Virtual Private Cloud (Amazon VPC) enables you to launch AWS resources into a virtual network that you've defined. This virtual network closely resembles a traditional network that you'd operate in your own data center, with the benefits of using the scalable infrastructure of AWS.  Configure firewall, availability zones, network sider address ranges,  Network ACL's, route tables etc.", 
            "title": "VPC : Virtual Private Cloud"
        }, 
        {
            "location": "/aws/services/networking-and-content-delivery/#cloudfront", 
            "text": "Amazons content delivery network service.", 
            "title": "CloudFront"
        }, 
        {
            "location": "/aws/services/networking-and-content-delivery/#route-53", 
            "text": "Amazons DNS service.", 
            "title": "Route 53"
        }, 
        {
            "location": "/aws/services/networking-and-content-delivery/#api-gateway", 
            "text": "For creating a serverless website.  A way of creating your own API for other services to talk to.", 
            "title": "API Gateway"
        }, 
        {
            "location": "/aws/services/networking-and-content-delivery/#direct-connect", 
            "text": "Is a way of running a dedicated line from your Corporate head office or data center to AWS.", 
            "title": "Direct connect"
        }, 
        {
            "location": "/aws/services/developer-tools/", 
            "text": "Developer tools\n\n\nCodeStar\n\n\nFor managing your code and colaborating with other developers in the team.\n\n\nCodeCommit\n\n\nA place to store your souce code. Git repositories on AWS.\n\n\nCodeBuild\n\n\nCompiles the code and run tests against it to producte software packages.\n\n\nCodeDeploy\n\n\nAutomates code deployment to your EC2 or on premise servers.\n\n\nCodePipeline\n\n\nContinuous delivery service to visualize and automate the steps required to release your software products.\n\n\nX-Ray\n\n\nTo debug and analyse serverless applications.\n\n\nCloud9\n\n\nThis is a IDE environment in AWS. A place where you can develop your code within your systems web browser.", 
            "title": "Developer Tools"
        }, 
        {
            "location": "/aws/services/developer-tools/#developer-tools", 
            "text": "", 
            "title": "Developer tools"
        }, 
        {
            "location": "/aws/services/developer-tools/#codestar", 
            "text": "For managing your code and colaborating with other developers in the team.", 
            "title": "CodeStar"
        }, 
        {
            "location": "/aws/services/developer-tools/#codecommit", 
            "text": "A place to store your souce code. Git repositories on AWS.", 
            "title": "CodeCommit"
        }, 
        {
            "location": "/aws/services/developer-tools/#codebuild", 
            "text": "Compiles the code and run tests against it to producte software packages.", 
            "title": "CodeBuild"
        }, 
        {
            "location": "/aws/services/developer-tools/#codedeploy", 
            "text": "Automates code deployment to your EC2 or on premise servers.", 
            "title": "CodeDeploy"
        }, 
        {
            "location": "/aws/services/developer-tools/#codepipeline", 
            "text": "Continuous delivery service to visualize and automate the steps required to release your software products.", 
            "title": "CodePipeline"
        }, 
        {
            "location": "/aws/services/developer-tools/#x-ray", 
            "text": "To debug and analyse serverless applications.", 
            "title": "X-Ray"
        }, 
        {
            "location": "/aws/services/developer-tools/#cloud9", 
            "text": "This is a IDE environment in AWS. A place where you can develop your code within your systems web browser.", 
            "title": "Cloud9"
        }, 
        {
            "location": "/aws/services/management-tools/", 
            "text": "Management tools\n\n\nCloudWatch\n\n\nIs a monitoring service.\n\n\nCloudFormation\n\n\nIt is a way of scripting infrastructure.\n\n\nAWS CloudFormation provides a common language for you to describe and provision all the infrastructure resources in your cloud environment. CloudFormation allows you to use a simple text file to model and provision, in an automated and secure manner\n\n\nWith a cloudformation template you can deploy your applications with ease.\n\n\nThe scripts are reusable.\n\n\nCloudTrail\n\n\nLogs changes to your AWS environment.\n\n\nIt is turned on by default and it keeps a trail of the changes for a week.\n\n\nIf turned on it makes it easy to determine if your environment is hacked.\n\n\nConfig\n\n\nMonitors the configuration of your AWS environment.\n\n\nMaintains a snapshot thus making it possible to move back and forward across weeks.\n\n\nVisualise your AWS environments.\n\n\nOpsWorks\n\n\nSimilar to elastic beanstack.\n\n\nUses chef and puppet to automate the environment.\n\n\nService catalog\n\n\nA way for managing a catalog of service allowed to use on the AWS environment.\n\n\nYou can decide on which Virtual server images, Operating systems. databases etc can be used on the AWS environment.\n\n\nBasically used by big organizations for governance and compliance requirements\n\n\nSystems Manager\n\n\nInterface for maintaining your AWS resources.\n\n\nTypically used for EC2.\n\n\nFor patch maintenance eg: security patches across thousands of EC2 instances.\n\n\nCan group all the resources by different departments or applications for planning the patch updates.\n\n\nTrusted Advisor\n\n\nWould give you advice on multiple deciplines like security, would advice if you have left any ports open that could be a security risk. It can tell you how you can save money on AWS. Can be thought of as an Advisor or an accountant that you trust and that gives you the best advice for your AWS environment.\n\n\nManaged services\n\n\nAmazon provides managed services for AWS, i.e., if you do not want to worry about your EC2 instances or the auto scale feature you can opt for the managed services.", 
            "title": "Management Tools"
        }, 
        {
            "location": "/aws/services/management-tools/#management-tools", 
            "text": "", 
            "title": "Management tools"
        }, 
        {
            "location": "/aws/services/management-tools/#cloudwatch", 
            "text": "Is a monitoring service.", 
            "title": "CloudWatch"
        }, 
        {
            "location": "/aws/services/management-tools/#cloudformation", 
            "text": "It is a way of scripting infrastructure.  AWS CloudFormation provides a common language for you to describe and provision all the infrastructure resources in your cloud environment. CloudFormation allows you to use a simple text file to model and provision, in an automated and secure manner  With a cloudformation template you can deploy your applications with ease.  The scripts are reusable.", 
            "title": "CloudFormation"
        }, 
        {
            "location": "/aws/services/management-tools/#cloudtrail", 
            "text": "Logs changes to your AWS environment.  It is turned on by default and it keeps a trail of the changes for a week.  If turned on it makes it easy to determine if your environment is hacked.", 
            "title": "CloudTrail"
        }, 
        {
            "location": "/aws/services/management-tools/#config", 
            "text": "Monitors the configuration of your AWS environment.  Maintains a snapshot thus making it possible to move back and forward across weeks.  Visualise your AWS environments.", 
            "title": "Config"
        }, 
        {
            "location": "/aws/services/management-tools/#opsworks", 
            "text": "Similar to elastic beanstack.  Uses chef and puppet to automate the environment.", 
            "title": "OpsWorks"
        }, 
        {
            "location": "/aws/services/management-tools/#service-catalog", 
            "text": "A way for managing a catalog of service allowed to use on the AWS environment.  You can decide on which Virtual server images, Operating systems. databases etc can be used on the AWS environment.  Basically used by big organizations for governance and compliance requirements", 
            "title": "Service catalog"
        }, 
        {
            "location": "/aws/services/management-tools/#systems-manager", 
            "text": "Interface for maintaining your AWS resources.  Typically used for EC2.  For patch maintenance eg: security patches across thousands of EC2 instances.  Can group all the resources by different departments or applications for planning the patch updates.", 
            "title": "Systems Manager"
        }, 
        {
            "location": "/aws/services/management-tools/#trusted-advisor", 
            "text": "Would give you advice on multiple deciplines like security, would advice if you have left any ports open that could be a security risk. It can tell you how you can save money on AWS. Can be thought of as an Advisor or an accountant that you trust and that gives you the best advice for your AWS environment.", 
            "title": "Trusted Advisor"
        }, 
        {
            "location": "/aws/services/management-tools/#managed-services", 
            "text": "Amazon provides managed services for AWS, i.e., if you do not want to worry about your EC2 instances or the auto scale feature you can opt for the managed services.", 
            "title": "Managed services"
        }, 
        {
            "location": "/aws/services/machine-learning/", 
            "text": "Machine Learning\n\n\nPolly\n\n\nTurns text into speech.\n\n\nCan choose different languages and accents.\n\n\nLex\n\n\nAlexa service.\n\n\nRekognition\n\n\nCan upload a picture and it will recognize it and let you know what elements are there in the picture.\n\n\nTranslate\n\n\nTranslate languages. Similar to google translate\n\n\nTranscribe\n\n\nAutomatic speech recognition. Turns speech into text.", 
            "title": "Machine Learning"
        }, 
        {
            "location": "/aws/services/machine-learning/#machine-learning", 
            "text": "", 
            "title": "Machine Learning"
        }, 
        {
            "location": "/aws/services/machine-learning/#polly", 
            "text": "Turns text into speech.  Can choose different languages and accents.", 
            "title": "Polly"
        }, 
        {
            "location": "/aws/services/machine-learning/#lex", 
            "text": "Alexa service.", 
            "title": "Lex"
        }, 
        {
            "location": "/aws/services/machine-learning/#rekognition", 
            "text": "Can upload a picture and it will recognize it and let you know what elements are there in the picture.", 
            "title": "Rekognition"
        }, 
        {
            "location": "/aws/services/machine-learning/#translate", 
            "text": "Translate languages. Similar to google translate", 
            "title": "Translate"
        }, 
        {
            "location": "/aws/services/machine-learning/#transcribe", 
            "text": "Automatic speech recognition. Turns speech into text.", 
            "title": "Transcribe"
        }, 
        {
            "location": "/aws/services/analytics/", 
            "text": "Analytics\n\n\nAthena\n\n\nLooks through the S3 bucket data and returns results.\n\n\nEMR : Elastic Map Reduce\n\n\nFor processing large amounts of data for big data solutions.\n\n\nCloudSearch and Elastic Search Service\n\n\nSearch services in AWS.\n\n\nKinesis\n\n\nWay of ingesting large amount of data into AWS. Social media feeds etc.\n\n\nQuickSight\n\n\nAmazons business intelligence tool.\n\n\nData pipeline\n\n\nMoving data between different AWS services.\n\n\nGlue\n\n\nUsed for ETL [Extract transform and load]", 
            "title": "Analytics"
        }, 
        {
            "location": "/aws/services/analytics/#analytics", 
            "text": "", 
            "title": "Analytics"
        }, 
        {
            "location": "/aws/services/analytics/#athena", 
            "text": "Looks through the S3 bucket data and returns results.", 
            "title": "Athena"
        }, 
        {
            "location": "/aws/services/analytics/#emr-elastic-map-reduce", 
            "text": "For processing large amounts of data for big data solutions.", 
            "title": "EMR : Elastic Map Reduce"
        }, 
        {
            "location": "/aws/services/analytics/#cloudsearch-and-elastic-search-service", 
            "text": "Search services in AWS.", 
            "title": "CloudSearch and Elastic Search Service"
        }, 
        {
            "location": "/aws/services/analytics/#kinesis", 
            "text": "Way of ingesting large amount of data into AWS. Social media feeds etc.", 
            "title": "Kinesis"
        }, 
        {
            "location": "/aws/services/analytics/#quicksight", 
            "text": "Amazons business intelligence tool.", 
            "title": "QuickSight"
        }, 
        {
            "location": "/aws/services/analytics/#data-pipeline", 
            "text": "Moving data between different AWS services.", 
            "title": "Data pipeline"
        }, 
        {
            "location": "/aws/services/analytics/#glue", 
            "text": "Used for ETL [Extract transform and load]", 
            "title": "Glue"
        }, 
        {
            "location": "/aws/services/mobile-services/", 
            "text": "Mobile services\n\n\nMobile hub\n\n\nManagement console for mobile applications.\n\n\nPinpoint\n\n\nFor using targetted push notifications.\n\n\nAppSync\n\n\nUpdates web and mobile data. Updates data from the cloud when the phone comes back online after being offline from sometime.\n\n\nDevice Farm\n\n\nTest mobile application on real android and ios devices.\n\n\nMobile Analytics\n\n\nAnalytics for your mobile application", 
            "title": "Mobile Services"
        }, 
        {
            "location": "/aws/services/mobile-services/#mobile-services", 
            "text": "", 
            "title": "Mobile services"
        }, 
        {
            "location": "/aws/services/mobile-services/#mobile-hub", 
            "text": "Management console for mobile applications.", 
            "title": "Mobile hub"
        }, 
        {
            "location": "/aws/services/mobile-services/#pinpoint", 
            "text": "For using targetted push notifications.", 
            "title": "Pinpoint"
        }, 
        {
            "location": "/aws/services/mobile-services/#appsync", 
            "text": "Updates web and mobile data. Updates data from the cloud when the phone comes back online after being offline from sometime.", 
            "title": "AppSync"
        }, 
        {
            "location": "/aws/services/mobile-services/#device-farm", 
            "text": "Test mobile application on real android and ios devices.", 
            "title": "Device Farm"
        }, 
        {
            "location": "/aws/services/mobile-services/#mobile-analytics", 
            "text": "Analytics for your mobile application", 
            "title": "Mobile Analytics"
        }, 
        {
            "location": "/aws/services/application-integration/", 
            "text": "Application Integration\n\n\nStep functions\n\n\nManaging your lamda functions and manage the steps to go through it.\n\n\nAmazon MQ\n\n\nFor message queues. similar to Rabbit MQ.\n\n\nSNS\n\n\nA notification service. Will be setting a billing alarm as part of the course.\n\n\nSQS\n\n\nOne of the oldest services.\n\n\nA way of decoupling your infrastructure.\n\n\nSWF : Simple Workflow Service\n\n\nCustomer engagement\n\n\nConnect\n\n\nA contact center as a service. Similar to having a call center on the cloud.\n\n\nSimple email service\n\n\nA great way of sending large amount of emails.", 
            "title": "Application Integration"
        }, 
        {
            "location": "/aws/services/application-integration/#application-integration", 
            "text": "", 
            "title": "Application Integration"
        }, 
        {
            "location": "/aws/services/application-integration/#step-functions", 
            "text": "Managing your lamda functions and manage the steps to go through it.", 
            "title": "Step functions"
        }, 
        {
            "location": "/aws/services/application-integration/#amazon-mq", 
            "text": "For message queues. similar to Rabbit MQ.", 
            "title": "Amazon MQ"
        }, 
        {
            "location": "/aws/services/application-integration/#sns", 
            "text": "A notification service. Will be setting a billing alarm as part of the course.", 
            "title": "SNS"
        }, 
        {
            "location": "/aws/services/application-integration/#sqs", 
            "text": "One of the oldest services.  A way of decoupling your infrastructure.", 
            "title": "SQS"
        }, 
        {
            "location": "/aws/services/application-integration/#swf-simple-workflow-service", 
            "text": "", 
            "title": "SWF : Simple Workflow Service"
        }, 
        {
            "location": "/aws/services/application-integration/#customer-engagement", 
            "text": "", 
            "title": "Customer engagement"
        }, 
        {
            "location": "/aws/services/application-integration/#connect", 
            "text": "A contact center as a service. Similar to having a call center on the cloud.", 
            "title": "Connect"
        }, 
        {
            "location": "/aws/services/application-integration/#simple-email-service", 
            "text": "A great way of sending large amount of emails.", 
            "title": "Simple email service"
        }, 
        {
            "location": "/aws/services/customer-engagement/", 
            "text": "Customer engagement\n\n\nConnect\n\n\nA contact center as a service. Similar to having a call center on the cloud.\n\n\nSimple email service\n\n\nA great way of sending large amount of emails.", 
            "title": "Customer Engagement"
        }, 
        {
            "location": "/aws/services/customer-engagement/#customer-engagement", 
            "text": "", 
            "title": "Customer engagement"
        }, 
        {
            "location": "/aws/services/customer-engagement/#connect", 
            "text": "A contact center as a service. Similar to having a call center on the cloud.", 
            "title": "Connect"
        }, 
        {
            "location": "/aws/services/customer-engagement/#simple-email-service", 
            "text": "A great way of sending large amount of emails.", 
            "title": "Simple email service"
        }, 
        {
            "location": "/aws/services/business-productivity/", 
            "text": "Business Productivity\n\n\nAlexa for Business\n\n\nUse it to dial into a meeting room or log a request for printer problems.\n\n\nChime\n\n\nLike google hangout. Record meetings.\n\n\nWork Docs\n\n\nLike a dropbox in AWS.\n\n\nWorkMail\n\n\nLike office 365 services in AWS.", 
            "title": "Business Productivity"
        }, 
        {
            "location": "/aws/services/business-productivity/#business-productivity", 
            "text": "", 
            "title": "Business Productivity"
        }, 
        {
            "location": "/aws/services/business-productivity/#alexa-for-business", 
            "text": "Use it to dial into a meeting room or log a request for printer problems.", 
            "title": "Alexa for Business"
        }, 
        {
            "location": "/aws/services/business-productivity/#chime", 
            "text": "Like google hangout. Record meetings.", 
            "title": "Chime"
        }, 
        {
            "location": "/aws/services/business-productivity/#work-docs", 
            "text": "Like a dropbox in AWS.", 
            "title": "Work Docs"
        }, 
        {
            "location": "/aws/services/business-productivity/#workmail", 
            "text": "Like office 365 services in AWS.", 
            "title": "WorkMail"
        }, 
        {
            "location": "/aws/services/desktop-and-app-streaming/", 
            "text": "Desktop and App Streaming\n\n\nWorkspaces\n\n\nIs a VDI short for Virtual Desktop Infrastructure solution. Accessing a desktop on the cloud on your device.\n\n\nAppStream 2.0\n\n\nWay of live streaming the applications. Like Citrix.", 
            "title": "Desktop and App Streaming"
        }, 
        {
            "location": "/aws/services/desktop-and-app-streaming/#desktop-and-app-streaming", 
            "text": "", 
            "title": "Desktop and App Streaming"
        }, 
        {
            "location": "/aws/services/desktop-and-app-streaming/#workspaces", 
            "text": "Is a VDI short for Virtual Desktop Infrastructure solution. Accessing a desktop on the cloud on your device.", 
            "title": "Workspaces"
        }, 
        {
            "location": "/aws/services/desktop-and-app-streaming/#appstream-20", 
            "text": "Way of live streaming the applications. Like Citrix.", 
            "title": "AppStream 2.0"
        }, 
        {
            "location": "/aws/services/internet-of-things/", 
            "text": "IOT Internet Of Things\n\n\niOT\n\n\niOT Device Management\n\n\nFreeRTOS\n\n\nGreengrass", 
            "title": "Internet Of Things"
        }, 
        {
            "location": "/aws/services/internet-of-things/#iot-internet-of-things", 
            "text": "", 
            "title": "IOT Internet Of Things"
        }, 
        {
            "location": "/aws/services/internet-of-things/#iot", 
            "text": "", 
            "title": "iOT"
        }, 
        {
            "location": "/aws/services/internet-of-things/#iot-device-management", 
            "text": "", 
            "title": "iOT Device Management"
        }, 
        {
            "location": "/aws/services/internet-of-things/#freertos", 
            "text": "", 
            "title": "FreeRTOS"
        }, 
        {
            "location": "/aws/services/internet-of-things/#greengrass", 
            "text": "", 
            "title": "Greengrass"
        }, 
        {
            "location": "/aws/services/game-development/", 
            "text": "Game Development\n\n\nGameLift\n\n\nService to help you develop games.", 
            "title": "Game Development"
        }, 
        {
            "location": "/aws/services/game-development/#game-development", 
            "text": "", 
            "title": "Game Development"
        }, 
        {
            "location": "/aws/services/game-development/#gamelift", 
            "text": "Service to help you develop games.", 
            "title": "GameLift"
        }
    ]
}